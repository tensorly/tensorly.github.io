
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Demonstration of PARAFAC2 &#8212; TensorLy: Tensor Learning in Python</title> 
<link rel="stylesheet" href="../../_static/tensorly_style.css">
<link rel="apple-touch-icon" sizes="180x180" href="../../_static/favicon/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="../../_static/favicon/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="../../_static/favicon/favicon-16x16.png">
<link rel="manifest" href="../../_static/favicon/site.webmanifest">
<link rel="mask-icon" href="../../_static/favicon/safari-pinned-tab.svg" color="#5bbad5">
<link rel="shortcut icon" href="../../_static/favicon/favicon.ico">
<meta name="theme-color" content="#ffffff">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/tensorly_style.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css" />

  
    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
 <script src="../../_static/navbar_burger.js"></script>
 <script defer src="https://use.fontawesome.com/releases/v5.14.0/js/all.js"></script>
 
<script async src="https://www.googletagmanager.com/gtag/js?id=G-3V91QCZR03"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-3V91QCZR03');
</script>
    <link rel="author" title="About these documents" href="../../about.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="CP tensor regression" href="../regression/plot_cp_regression.html" />
    <link rel="prev" title="Non-negative CP decomposition in Tensorly &gt;=0.6" href="plot_nn_cp_hals.html" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">

  </head>
<body  class="has-navbar-fixed-top">

  <header>
    <navbar>
      <nav class="navbar top-navbar is-fixed-top has-shadow is-flex-wrap-wrap" role="navigation" aria-label="main top navigation">
        <div class="navbar-brand">
        <!-- Always displayed, last item has to be navbar-burger -->

          <a class="navbar-item" href="../../index.html">
            <img src="../../_static/logo_tensorly.png" height="28">
          </a>

          <!-- <a class="navbar-item is-hidden-desktop" href="../../index.html">
            <span class="icon"><i class="fa fa-home" aria-hidden="true"></i></span>
          </a> -->
          <a class="navbar-item is-hidden-desktop" href="https://github.com/tensorly/tensorly" target="_blank">
              <span class="icon"><i class="fab fa-github"></i></span>
          </a>

          <a role="button" class="navbar-burger" data-target="top-nav-menu" aria-label="menu" aria-expanded="false">
            <span aria-hidden="true"></span>
            <span aria-hidden="true"></span>
            <span aria-hidden="true"></span>
          </a>

        </div>
        
        <div class="navbar-menu" id="top-nav-menu">
        <!-- only on larger displays (> 1024px) -->

          <div class="navbar-start">
          <!-- RIGHT -->
            <a class="navbar-item" href="../../installation.html">
              Install
            </a>
            <a class="navbar-item" href="../../user_guide/index.html">
              User Guide
            </a>
            <a class="navbar-item" href="../../modules/api.html">
              API
            </a>
            <a class="navbar-item" href="../index.html">
              Examples
            </a>
            <a class="navbar-item" href="../../about.html">
              About Us
            </a>
            <a class="navbar-item" href="https://github.com/JeanKossaifi/tensorly-notebooks" target="_blank">
              Notebooks
            </a>

          </div>
        
          <div class="navbar-end">
            <div class="navbar-item">
            <!-- LEFT -->

            <!-- <a class="navbar-item is-hidden-touch" href="../../index.html">
              <span class="icon-text">
                <span class="icon">
                  <i class="fa fa-home"></i>
                </span>
                <span>Home</span>
              </span>
              <span class="icon"><i class="fa fa-home" aria-hidden="true"></i></span>
            </a> -->
            <a class="button is-hidden-touch is-dark" href="https://github.com/tensorly/tensorly" target="_blank">
              <span class="icon-text">
                <span class="icon is-large">
                  <i class="fab fa-github"></i>
                </span>
                <span>Github</span>
              </span>
                <!-- <span class="icon"><i class="fab fa-github"></i></span> -->
            </a>

            </div> <!-- navbar item -->
          </div> <!-- navbar end -->
        </div> <!-- only large items -->

      </nav>
      
    </navbar>
  </header>

  <div id="column-container">
  <div class="columns is-mobile is-centered">
	
      <div class="column is-10-mobile is-one-third-tablet is-3-desktop is-hidden-mobile" id="sidebar">
    <!-- Side menu  -->
    <aside class="sticky-nav sidebar-menu">
<div class="sidebar-search">
  <form class="field" id="searchbox" role="search" action="../../search.html" method="get">
    <!-- <label class="label" id="searchlabel">Quick search</label> -->
    <div class="field has-addons">
      <div class="control is-expanded">
        <input class="input" type="text" placeholder="Search in TensorLy" name="q" aria-labelledby="searchlabel">
      </div>
      <div class="control">
        <input class="button is-info" type="submit" value="Go" />
      </div>
    </div>
  </form>
  <script>$('#searchbox').show(0);</script>
  <script>
  $(document).ready(function() {
    Document.highlightSearchWords = function() {
      var params = $.getQueryParameters();
      var terms = (params.highlight) ? params.highlight[0].split(/\s+/) : [];
      if (terms.length) {
        var body = $('div.body');
        if (!body.length) {
          body = $('body');
        }
        window.setTimeout(function() {
          $.each(terms, function() {
            body.highlightText(this.toLowerCase(), 'highlighted');
          });
        }, 10);
        $('<p class="highlight-link"><a href="javascript:Documentation.' +
          'hideSearchWords()">' + _('Hide All')
          + '<span class="tag is-delete"></span>'
          + '</a></p>')
            .appendTo($('#searchbox'));
      }
    };
  });
  </script>
</div>
      
      <div class="sidebar-menu-toc">
      <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../installation.html">Installing tensorly</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../user_guide/index.html">User guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../modules/api.html">API reference</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">Gallery of examples</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../index.html#general-examples">General examples</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../index.html#tensor-decomposition">Tensor decomposition</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#tensor-regression-with-tensorly">Tensor regression with tensorly</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../development_guide/index.html">Development guide</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/JeanKossaifi/tensorly-notebooks">Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../about.html">About us</a></li>
</ul>
 
      </div>
    </aside>
  </div>
  

    <div class="column main-column">

      <!-- Main content  -->
      <section class="main-section">

        <!-- Toggle menu button -->
		
        <div class="side-menu-toggle">
          <button class="button" id="toggle-sidebar" onclick="toggle_sidebar()">
            <span class="icon"><i class="fa fa-bars" aria-hidden="true"></i></span>
            <span>menu</span> 
          </button>
        </div>
        

        <div class="content main-content">
          
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-decomposition-plot-parafac2-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<section class="sphx-glr-example-title" id="demonstration-of-parafac2">
<span id="sphx-glr-auto-examples-decomposition-plot-parafac2-py"></span><h1>Demonstration of PARAFAC2</h1>
<p>Example of how to use the PARAFAC2 algorithm.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">numpy.linalg</span> <span class="k">as</span> <span class="nn">la</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">tensorly</span> <span class="k">as</span> <span class="nn">tl</span>
<span class="kn">from</span> <span class="nn">tensorly.decomposition</span> <span class="kn">import</span> <span class="n">parafac2</span>
<span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">linear_sum_assignment</span>
</pre></div>
</div>
<section id="create-synthetic-tensor">
<h2>Create synthetic tensor</h2>
<p>Here, we create a random tensor that follows the PARAFAC2 constraints found
inx <a class="reference internal" href="#kiers-et-al-1999">(Kiers et al 1999)</a>.</p>
<p>This particular tensor,
<span class="math notranslate nohighlight">\(\mathcal{X} \in \mathbb{R}^{I\times J \times K}\)</span>, is a shifted
CP tensor, that is, a tensor on the form:</p>
<div class="math notranslate nohighlight">
\[\mathcal{X}_{ijk} = \sum_{r=1}^R A_{ir} B_{\sigma_i(j) r} C_{kr},\]</div>
<p>where <span class="math notranslate nohighlight">\(\sigma_i\)</span> is a cyclic permutation of <span class="math notranslate nohighlight">\(J\)</span> elements.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set parameters</span>
<span class="n">true_rank</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">I</span><span class="p">,</span> <span class="n">J</span><span class="p">,</span> <span class="n">K</span> <span class="o">=</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">20</span>
<span class="n">noise_rate</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Generate random matrices</span>
<span class="n">A_factor_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">I</span><span class="p">,</span> <span class="n">true_rank</span><span class="p">))</span>
<span class="n">B_factor_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">J</span><span class="p">,</span> <span class="n">true_rank</span><span class="p">))</span>
<span class="n">C_factor_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="n">true_rank</span><span class="p">))</span>

<span class="c1"># Normalised factor matrices</span>
<span class="n">A_normalised</span> <span class="o">=</span> <span class="n">A_factor_matrix</span><span class="o">/</span><span class="n">la</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">A_factor_matrix</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">B_normalised</span> <span class="o">=</span> <span class="n">B_factor_matrix</span><span class="o">/</span><span class="n">la</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">B_factor_matrix</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">C_normalised</span> <span class="o">=</span> <span class="n">C_factor_matrix</span><span class="o">/</span><span class="n">la</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">C_factor_matrix</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Generate the shifted factor matrix</span>
<span class="n">B_factor_matrices</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">roll</span><span class="p">(</span><span class="n">B_factor_matrix</span><span class="p">,</span> <span class="n">shift</span><span class="o">=</span><span class="n">i</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">I</span><span class="p">)]</span>
<span class="n">Bs_normalised</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">roll</span><span class="p">(</span><span class="n">B_normalised</span><span class="p">,</span> <span class="n">shift</span><span class="o">=</span><span class="n">i</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">I</span><span class="p">)]</span>

<span class="c1"># Construct the tensor</span>
<span class="n">tensor</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;ir,ijr,kr-&gt;ijk&#39;</span><span class="p">,</span> <span class="n">A_factor_matrix</span><span class="p">,</span> <span class="n">B_factor_matrices</span><span class="p">,</span> <span class="n">C_factor_matrix</span><span class="p">)</span>

<span class="c1"># Add noise</span>
<span class="n">noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">noise</span> <span class="o">/=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">noise</span><span class="p">)</span>
<span class="n">noise</span> <span class="o">*=</span> <span class="n">noise_rate</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>
<span class="n">tensor</span> <span class="o">+=</span> <span class="n">noise</span>
</pre></div>
</div>
</section>
<section id="fit-a-parafac2-tensor">
<h2>Fit a PARAFAC2 tensor</h2>
<p>To avoid local minima, we initialise and fit 10 models and choose the one
with the lowest error</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">best_err</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
<span class="n">decomposition</span> <span class="o">=</span> <span class="kc">None</span>

<span class="k">for</span> <span class="n">run</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Training model </span><span class="si">{</span><span class="n">run</span><span class="si">}</span><span class="s1">...&#39;</span><span class="p">)</span>
    <span class="n">trial_decomposition</span><span class="p">,</span> <span class="n">trial_errs</span> <span class="o">=</span> <span class="n">parafac2</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">true_rank</span><span class="p">,</span> <span class="n">return_errors</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">,</span> <span class="n">n_iter_max</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">run</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Number of iterations: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">trial_errs</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Final error: </span><span class="si">{</span><span class="n">trial_errs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">best_err</span> <span class="o">&gt;</span> <span class="n">trial_errs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
        <span class="n">best_err</span> <span class="o">=</span> <span class="n">trial_errs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">err</span> <span class="o">=</span> <span class="n">trial_errs</span>
        <span class="n">decomposition</span> <span class="o">=</span> <span class="n">trial_decomposition</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;-------------------------------&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Best model error: </span><span class="si">{</span><span class="n">best_err</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Training model 0...
Number of iterations: 500
Final error: 0.09204720575424472
-------------------------------
Training model 1...
Number of iterations: 500
Final error: 0.09204726856012718
-------------------------------
Training model 2...
Number of iterations: 500
Final error: 0.09269711804187236
-------------------------------
Training model 3...
Number of iterations: 392
Final error: 0.09204692795621945
-------------------------------
Training model 4...
Number of iterations: 415
Final error: 0.09204692959223094
-------------------------------
Training model 5...
Number of iterations: 500
Final error: 0.09291065541285955
-------------------------------
Training model 6...
Number of iterations: 364
Final error: 0.09204692769766268
-------------------------------
Training model 7...
Number of iterations: 424
Final error: 0.09204692883956123
-------------------------------
Training model 8...
Number of iterations: 481
Final error: 0.09204693125447479
-------------------------------
Training model 9...
Number of iterations: 500
Final error: 0.09205635789758466
-------------------------------
Best model error: 0.09204692769766268
</pre></div>
</div>
<p>A decomposition is a wrapper object for three variables: the <em>weights</em>,
the <em>factor matrices</em> and the <em>projection matrices</em>. The weights are similar
to the output of a CP decomposition. The factor matrices and projection
matrices are somewhat different. For a CP decomposition, we only have the
weights and the factor matrices. However, since the PARAFAC2 factor matrices
for the second mode is given by</p>
<div class="math notranslate nohighlight">
\[B_i = P_i B,\]</div>
<p>where <span class="math notranslate nohighlight">\(B\)</span> is an <span class="math notranslate nohighlight">\(R \times R\)</span> matrix and <span class="math notranslate nohighlight">\(P_i\)</span> is an
<span class="math notranslate nohighlight">\(I \times R\)</span> projection matrix, we cannot store the factor matrices
the same as for a CP decomposition.</p>
<p>Instead, we store the factor matrix along the first mode (<span class="math notranslate nohighlight">\(A\)</span>), the
“blueprint” matrix for the second mode (<span class="math notranslate nohighlight">\(B\)</span>) and the factor matrix
along the third mode (<span class="math notranslate nohighlight">\(C\)</span>) in one tuple and the projection matrices,
<span class="math notranslate nohighlight">\(P_i\)</span>, in a separate tuple.</p>
<p>If we wish to extract the informative <span class="math notranslate nohighlight">\(B_i\)</span> factor matrices, then we
use the <code class="docutils literal notranslate"><span class="pre">tensorly.parafac2_tensor.apply_projection_matrices</span></code> function on
the PARAFAC2 tensor instance to get another wrapper object for two
variables: <em>weights</em> and <em>factor matrices</em>. However, now, the second element
of the factor matrices tuple is now a list of factor matrices, one for each
frontal slice of the tensor.</p>
<p>Likewise, if we wish to construct the tensor or the frontal slices, then we
can use the <code class="docutils literal notranslate"><span class="pre">tensorly.parafac2_tensor.parafac2_to_tensor</span></code> function. If the
decomposed dataset consisted of uneven-length frontal slices, then we can
use the <code class="docutils literal notranslate"><span class="pre">tensorly.parafac2_tensor.parafac2_to_slices</span></code> function to get a
list of frontal slices.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">est_tensor</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">parafac2_tensor</span><span class="o">.</span><span class="n">parafac2_to_tensor</span><span class="p">(</span><span class="n">decomposition</span><span class="p">)</span>
<span class="n">est_weights</span><span class="p">,</span> <span class="p">(</span><span class="n">est_A</span><span class="p">,</span> <span class="n">est_B</span><span class="p">,</span> <span class="n">est_C</span><span class="p">)</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">parafac2_tensor</span><span class="o">.</span><span class="n">apply_parafac2_projections</span><span class="p">(</span><span class="n">decomposition</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="compute-performance-metrics">
<h2>Compute performance metrics</h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">reconstruction_error</span> <span class="o">=</span> <span class="n">la</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">est_tensor</span> <span class="o">-</span> <span class="n">tensor</span><span class="p">)</span>
<span class="n">recovery_rate</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">reconstruction_error</span><span class="o">/</span><span class="n">la</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">recovery_rate</span><span class="si">:</span><span class="s1">2.0%</span><span class="si">}</span><span class="s1"> of the data is explained by the model, which is expected with noise rate: </span><span class="si">{</span><span class="n">noise_rate</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>


<span class="c1"># To evaluate how well the original structure is recovered, we calculate the tucker congruence coefficient.</span>

<span class="n">est_A</span><span class="p">,</span> <span class="n">est_projected_Bs</span><span class="p">,</span> <span class="n">est_C</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">parafac2_tensor</span><span class="o">.</span><span class="n">apply_parafac2_projections</span><span class="p">(</span><span class="n">decomposition</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>

<span class="n">sign</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">est_A</span><span class="p">)</span>
<span class="n">est_A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">est_A</span><span class="p">)</span>
<span class="n">est_projected_Bs</span> <span class="o">=</span> <span class="n">sign</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span><span class="o">*</span><span class="n">est_projected_Bs</span>

<span class="n">est_A_normalised</span> <span class="o">=</span> <span class="n">est_A</span><span class="o">/</span><span class="n">la</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">est_A</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">est_Bs_normalised</span> <span class="o">=</span> <span class="p">[</span><span class="n">est_B</span><span class="o">/</span><span class="n">la</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">est_B</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">est_B</span> <span class="ow">in</span> <span class="n">est_projected_Bs</span><span class="p">]</span>
<span class="n">est_C_normalised</span> <span class="o">=</span> <span class="n">est_C</span><span class="o">/</span><span class="n">la</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">est_C</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">B_corr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">est_Bs_normalised</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">true_rank</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="nd">@np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">Bs_normalised</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">true_rank</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">est_Bs_normalised</span><span class="p">)</span>
<span class="n">A_corr</span> <span class="o">=</span> <span class="n">est_A_normalised</span><span class="o">.</span><span class="n">T</span><span class="nd">@A_normalised</span>
<span class="n">C_corr</span> <span class="o">=</span> <span class="n">est_C_normalised</span><span class="o">.</span><span class="n">T</span><span class="nd">@C_normalised</span>

<span class="n">corr</span> <span class="o">=</span> <span class="n">A_corr</span><span class="o">*</span><span class="n">B_corr</span><span class="o">*</span><span class="n">C_corr</span>
<span class="n">permutation</span> <span class="o">=</span> <span class="n">linear_sum_assignment</span><span class="p">(</span><span class="o">-</span><span class="n">corr</span><span class="p">)</span>  <span class="c1"># Old versions of scipy does not support maximising, from scipy v1.4, you can pass `corr` and `maximize=True` instead of `-corr` to maximise the sum.</span>

<span class="n">congruence_coefficient</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">corr</span><span class="p">[</span><span class="n">permutation</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Average tucker congruence coefficient: </span><span class="si">{</span><span class="n">congruence_coefficient</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>91% of the data is explained by the model, which is expected with noise rate: 0.1
Average tucker congruence coefficient: 0.9947046512423605
</pre></div>
</div>
</section>
<section id="visualize-the-components">
<h2>Visualize the components</h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Find the best permutation so that we can plot the estimated components on top of the true components</span>
<span class="n">permutation</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">A_corr</span><span class="o">*</span><span class="n">B_corr</span><span class="o">*</span><span class="n">C_corr</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>


<span class="c1"># Create plots of each component vector for each mode</span>
<span class="c1"># (We just look at one of the B_i matrices)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">true_rank</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">3</span><span class="o">*</span><span class="n">true_rank</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
<span class="n">i</span> <span class="o">=</span> <span class="mi">0</span> <span class="c1"># What slice, B_i, we look at for the B mode</span>

<span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">true_rank</span><span class="p">):</span>

    <span class="c1"># Plot true and estimated components for mode A</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">r</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">((</span><span class="n">A_normalised</span><span class="p">[:,</span> <span class="n">r</span><span class="p">]),</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;True&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">r</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">((</span><span class="n">est_A_normalised</span><span class="p">[:,</span> <span class="n">permutation</span><span class="p">[</span><span class="n">r</span><span class="p">]]),</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Estimated&#39;</span><span class="p">)</span>

    <span class="c1"># Labels for the different components</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">r</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Component </span><span class="si">{</span><span class="n">r</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="c1"># Plot true and estimated components for mode C</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">r</span><span class="p">][</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">C_normalised</span><span class="p">[:,</span> <span class="n">r</span><span class="p">])</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">r</span><span class="p">][</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">est_C_normalised</span><span class="p">[:,</span> <span class="n">permutation</span><span class="p">[</span><span class="n">r</span><span class="p">]],</span> <span class="s1">&#39;--&#39;</span><span class="p">)</span>

    <span class="c1"># Plot true components for mode B</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">r</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">Bs_normalised</span><span class="p">[</span><span class="n">i</span><span class="p">][:,</span> <span class="n">r</span><span class="p">])</span>

    <span class="c1"># Get the signs so that we can flip the B mode factor matrices</span>
    <span class="n">A_sign</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">est_A_normalised</span><span class="p">)</span>

    <span class="c1"># Plot estimated components for mode B (after sign correction)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">r</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">A_sign</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">r</span><span class="p">]</span><span class="o">*</span><span class="n">est_Bs_normalised</span><span class="p">[</span><span class="n">i</span><span class="p">][:,</span> <span class="n">permutation</span><span class="p">[</span><span class="n">r</span><span class="p">]],</span> <span class="s1">&#39;--&#39;</span><span class="p">)</span>

<span class="c1"># Titles for the different modes</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;A mode&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;C mode&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;B mode (slice </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>

<span class="c1"># Create a legend for the entire figure</span>
<span class="n">handles</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span>  <span class="n">axes</span><span class="p">[</span><span class="n">r</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_legend_handles_labels</span><span class="p">()</span>
<span class="n">fig</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">handles</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper center&#39;</span><span class="p">,</span> <span class="n">ncol</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_plot_parafac2_001.png" srcset="../../_images/sphx_glr_plot_parafac2_001.png" alt="A mode, B mode (slice 0), C mode" class = "sphx-glr-single-img"/><p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.legend.Legend object at 0x7fcdc9ab1ee0&gt;
</pre></div>
</div>
</section>
<section id="inspect-the-convergence-rate">
<h2>Inspect the convergence rate</h2>
<p>It can be interesting to look at the loss plot to make sure that we have
converged to a stationary point. We skip the first iteration since the
initial loss often dominate the rest of the plot, making it difficult
to check for convergence.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">loss_fig</span><span class="p">,</span> <span class="n">loss_ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">9</span><span class="o">/</span><span class="mf">1.6</span><span class="p">))</span>
<span class="n">loss_ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">err</span><span class="p">)),</span> <span class="n">err</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
<span class="n">loss_ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Iteration number&#39;</span><span class="p">)</span>
<span class="n">loss_ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Relative reconstruction error&#39;</span><span class="p">)</span>
<span class="n">mathematical_expression_of_loss</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;$\frac{\left|\left|\hat{\mathcal</span><span class="si">{X}</span><span class="s2">}\right|\right|_F}{\left|\left|\mathcal</span><span class="si">{X}</span><span class="s2">\right|\right|_F}$&quot;</span>
<span class="n">loss_ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Loss plot: </span><span class="si">{</span><span class="n">mathematical_expression_of_loss</span><span class="si">}</span><span class="s1"> </span><span class="se">\n</span><span class="s1"> (starting after first iteration)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">xticks</span> <span class="o">=</span> <span class="n">loss_ax</span><span class="o">.</span><span class="n">get_xticks</span><span class="p">()</span>
<span class="n">loss_ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">([</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">xticks</span><span class="p">[</span><span class="mi">1</span><span class="p">:]))</span>
<span class="n">loss_ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">err</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_plot_parafac2_002.png" srcset="../../_images/sphx_glr_plot_parafac2_002.png" alt="Loss plot: $\frac{\left|\left|\hat{\mathcal{X}}\right|\right|_F}{\left|\left|\mathcal{X}\right|\right|_F}$   (starting after first iteration)" class = "sphx-glr-single-img"/></section>
<section id="references">
<h2>References</h2>
<p id="kiers-et-al-1999">Kiers HA, Ten Berge JM, Bro R. <em>PARAFAC2—Part I.
A direct fitting algorithm for the PARAFAC2 model.</em>
<strong>Journal of Chemometrics: A Journal of the Chemometrics Society.</strong>
1999 May;13(3‐4):275-94. <a class="reference external" href="https://onlinelibrary.wiley.com/doi/abs/10.1002/(SICI)1099-128X(199905/08)13:3/4%3C275::AID-CEM543%3E3.0.CO;2-B">(Online version)</a></p>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  32.319 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-decomposition-plot-parafac2-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/32f8d624f9d1f7b561ad62798d8861ca/plot_parafac2.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_parafac2.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/8c1716b060db83a5d0c4cf467673c021/plot_parafac2.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_parafac2.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>


        </div>

		
        <nav class="pagination" role="navigation" aria-label="pagination">
    
    <a class="button is-medium pagination-previous" href="plot_nn_cp_hals.html" title="previous page" accesskey="p">
        <span class="icon">
            <i class="fa fa-arrow-circle-left"></i>
        </span>
        <span>Non-negative CP decomposition in Tensorly &gt;=0.6</span>
    </a>
    
    
    <a class="button is-medium pagination-next" href="../regression/plot_cp_regression.html" title="next page" accesskey="n">
        <span>CP tensor regression </span>
        <span class="icon">
            <i class="fa fa-arrow-circle-right"></i>
        </span>
    </a>
    
</nav>

        

      </section>

        <footer class="footer">
    <div class="content has-text-centered">
        <div class="block">
          &copy; Copyright 2016 - 2022, TensorLy Developers.<br/>
        </div>
    </div>
  </footer>

    </div>

	
    
    <div class="column is-hidden-touch is-2-desktop is-one-fifth-widescreen" id="localtoc-column">

    <aside class="sticky-nav localtoc">  
        <div class="menu menu-list">
        <p class="menu-label">On this page</p>
        <ul>
<li><a class="reference internal" href="#">Demonstration of PARAFAC2</a><ul>
<li><a class="reference internal" href="#create-synthetic-tensor">Create synthetic tensor</a></li>
<li><a class="reference internal" href="#fit-a-parafac2-tensor">Fit a PARAFAC2 tensor</a></li>
<li><a class="reference internal" href="#compute-performance-metrics">Compute performance metrics</a></li>
<li><a class="reference internal" href="#visualize-the-components">Visualize the components</a></li>
<li><a class="reference internal" href="#inspect-the-convergence-rate">Inspect the convergence rate</a></li>
<li><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
</ul>

        </div>
    </aside>
    </div>

    

  </div>
  </div>

  <!-- Include here scripts that need to be added after the page is loaded -->
  <script>
    function toggle_sidebar() {
        var element = document.getElementById("sidebar");
        var container = document.getElementById("column-container");
        var localtoccolumn = document.getElementById("localtoc-column");
        element.classList.toggle("hide-tablet");
        element.classList.toggle("is-hidden-mobile");
        container.classList.toggle("sidemenu-hidden");
        localtoccolumn.classList.toggle("is-one-fifth-widescreen");
        localtoccolumn.classList.toggle("is-2-desktop");
        localtoccolumn.classList.toggle("is-3-desktop");
    }
  </script> 



  </body>
</html>