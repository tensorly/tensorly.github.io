
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Non-negative Tucker decomposition in Tensorly &gt;=0.6 &#8212; TensorLy: Tensor Learning in Python</title> 
<link rel="stylesheet" href="../../_static/tensorly_style.css">
<link rel="apple-touch-icon" sizes="180x180" href="../../_static/favicon/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="../../_static/favicon/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="../../_static/favicon/favicon-16x16.png">
<link rel="manifest" href="../../_static/favicon/site.webmanifest">
<link rel="mask-icon" href="../../_static/favicon/safari-pinned-tab.svg" color="#5bbad5">
<link rel="shortcut icon" href="../../_static/favicon/favicon.ico">
<meta name="theme-color" content="#ffffff">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/tensorly_style.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css" />

  
    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
 <script src="../../_static/navbar_burger.js"></script>
 <script defer src="https://use.fontawesome.com/releases/v5.14.0/js/all.js"></script>
 
<script async src="https://www.googletagmanager.com/gtag/js?id=G-3V91QCZR03"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-3V91QCZR03');
</script>
    <link rel="author" title="About these documents" href="../../about.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Non-negative CP decomposition in Tensorly &gt;=0.6" href="plot_nn_cp_hals.html" />
    <link rel="prev" title="Image compression via tensor decomposition" href="plot_image_compression.html" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">

  </head>
<body  class="has-navbar-fixed-top">

  <header>
    <navbar>
      <nav class="navbar top-navbar is-fixed-top has-shadow is-flex-wrap-wrap" role="navigation" aria-label="main top navigation">
        <div class="navbar-brand">
        <!-- Always displayed, last item has to be navbar-burger -->

          <a class="navbar-item" href="../../index.html">
            <img src="../../_static/logo_tensorly.png" height="28">
          </a>

          <!-- <a class="navbar-item is-hidden-desktop" href="../../index.html">
            <span class="icon"><i class="fa fa-home" aria-hidden="true"></i></span>
          </a> -->
          <a class="navbar-item is-hidden-desktop" href="https://github.com/tensorly/tensorly" target="_blank">
              <span class="icon"><i class="fab fa-github"></i></span>
          </a>

          <a role="button" class="navbar-burger" data-target="top-nav-menu" aria-label="menu" aria-expanded="false">
            <span aria-hidden="true"></span>
            <span aria-hidden="true"></span>
            <span aria-hidden="true"></span>
          </a>

        </div>
        
        <div class="navbar-menu" id="top-nav-menu">
        <!-- only on larger displays (> 1024px) -->

          <div class="navbar-start">
          <!-- RIGHT -->
            <a class="navbar-item" href="../../installation.html">
              Install
            </a>
            <a class="navbar-item" href="../../user_guide/index.html">
              User Guide
            </a>
            <a class="navbar-item" href="../../modules/api.html">
              API
            </a>
            <a class="navbar-item" href="../index.html">
              Examples
            </a>
            <a class="navbar-item" href="../../about.html">
              About Us
            </a>
            <a class="navbar-item" href="https://github.com/JeanKossaifi/tensorly-notebooks" target="_blank">
              Notebooks
            </a>

          </div>
        
          <div class="navbar-end">
            <div class="navbar-item">
            <!-- LEFT -->

            <!-- <a class="navbar-item is-hidden-touch" href="../../index.html">
              <span class="icon-text">
                <span class="icon">
                  <i class="fa fa-home"></i>
                </span>
                <span>Home</span>
              </span>
              <span class="icon"><i class="fa fa-home" aria-hidden="true"></i></span>
            </a> -->
            <a class="button is-hidden-touch is-dark" href="https://github.com/tensorly/tensorly" target="_blank">
              <span class="icon-text">
                <span class="icon is-large">
                  <i class="fab fa-github"></i>
                </span>
                <span>Github</span>
              </span>
                <!-- <span class="icon"><i class="fab fa-github"></i></span> -->
            </a>

            </div> <!-- navbar item -->
          </div> <!-- navbar end -->
        </div> <!-- only large items -->

      </nav>
      
    </navbar>
  </header>

  <div id="column-container">
  <div class="columns is-mobile is-centered">
	
      <div class="column is-10-mobile is-one-third-tablet is-3-desktop is-hidden-mobile" id="sidebar">
    <!-- Side menu  -->
    <aside class="sticky-nav sidebar-menu">
<div class="sidebar-search">
  <form class="field" id="searchbox" role="search" action="../../search.html" method="get">
    <!-- <label class="label" id="searchlabel">Quick search</label> -->
    <div class="field has-addons">
      <div class="control is-expanded">
        <input class="input" type="text" placeholder="Search in TensorLy" name="q" aria-labelledby="searchlabel">
      </div>
      <div class="control">
        <input class="button is-info" type="submit" value="Go" />
      </div>
    </div>
  </form>
  <script>$('#searchbox').show(0);</script>
  <script>
  $(document).ready(function() {
    Document.highlightSearchWords = function() {
      var params = $.getQueryParameters();
      var terms = (params.highlight) ? params.highlight[0].split(/\s+/) : [];
      if (terms.length) {
        var body = $('div.body');
        if (!body.length) {
          body = $('body');
        }
        window.setTimeout(function() {
          $.each(terms, function() {
            body.highlightText(this.toLowerCase(), 'highlighted');
          });
        }, 10);
        $('<p class="highlight-link"><a href="javascript:Documentation.' +
          'hideSearchWords()">' + _('Hide All')
          + '<span class="tag is-delete"></span>'
          + '</a></p>')
            .appendTo($('#searchbox'));
      }
    };
  });
  </script>
</div>
      
      <div class="sidebar-menu-toc">
      <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../installation.html">Installing tensorly</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../user_guide/index.html">User guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../modules/api.html">API reference</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">Gallery of examples</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../index.html#general-examples">General examples</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../index.html#tensor-decomposition">Tensor decomposition</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#tensor-regression-with-tensorly">Tensor regression with tensorly</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../development_guide/index.html">Development guide</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/JeanKossaifi/tensorly-notebooks">Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../about.html">About us</a></li>
</ul>
 
      </div>
    </aside>
  </div>
  

    <div class="column main-column">

      <!-- Main content  -->
      <section class="main-section">

        <!-- Toggle menu button -->
		
        <div class="side-menu-toggle">
          <button class="button" id="toggle-sidebar" onclick="toggle_sidebar()">
            <span class="icon"><i class="fa fa-bars" aria-hidden="true"></i></span>
            <span>menu</span> 
          </button>
        </div>
        

        <div class="content main-content">
          
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-decomposition-plot-nn-tucker-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<section class="sphx-glr-example-title" id="non-negative-tucker-decomposition-in-tensorly-0-6">
<span id="sphx-glr-auto-examples-decomposition-plot-nn-tucker-py"></span><h1>Non-negative Tucker decomposition in Tensorly &gt;=0.6</h1>
<p>Example and comparison of Non-negative Tucker decompositions.</p>
<section id="introduction">
<h2>Introduction</h2>
<p>Since version 0.6 in Tensorly, two algorithms are available to compute non-negative
Tucker decomposition:</p>
<ol class="arabic simple">
<li><p>Multiplicative updates (MU) (already in Tensorly &lt; 0.6)</p></li>
<li><p>Non-negative Alternating Least Squares (ALS) using Hierarchical ALS (HALS)</p></li>
</ol>
<p>Non-negativity is an important constraint to handle for tensor decompositions.
One could expect that core and factors must have only non-negative values after
it is obtained from a non-negative tensor. Tucker decomposition includes core
(<span class="math notranslate nohighlight">\(G\)</span>) and factors (<span class="math notranslate nohighlight">\(A\)</span>, <span class="math notranslate nohighlight">\(B\)</span>, <span class="math notranslate nohighlight">\(C\)</span>).</p>
<div class="math notranslate nohighlight">
\[T = [| G; A, B , C |],\]</div>
<p>We need to solve the following problem for each factor (e.g. factor <span class="math notranslate nohighlight">\(A\)</span> here):</p>
<div class="math notranslate nohighlight">
\[\min_{A \geq 0} ||T_{[1]} - A\times G_{[1]}(B\times C)^T||_F^2,\]</div>
<p>Here, <span class="math notranslate nohighlight">\(G_{[i]}\)</span> represents ith mode unfolding of the core. To update
the core, we need the solve following problem:</p>
<div class="math notranslate nohighlight">
\[\min_{g \geq 0} ||t -   (A\times B \times C)\times g ||_F^2,\]</div>
<p>where <span class="math notranslate nohighlight">\(t\)</span> and <span class="math notranslate nohighlight">\(g\)</span> are the vectorized data tensor <span class="math notranslate nohighlight">\(T\)</span> and core <span class="math notranslate nohighlight">\(G\)</span>.</p>
<p>To update the factors, we will use HALS and to update the core, we have two
different algorithms Active Set (AS) and Fast Iterative Shrinkage-Thresholding
Algorithm (FISTA) in Tensorly. While FISTA is an accelerated gradient method for
non-negative or unconstrained problems, AS is the widely used non-negative
least square solution proposed by Lawson and Hanson in 1974. Both algorithms
return non-negative core and FISTA is the default algorithm for HALS Tucker
decomposition in Tensorly.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorly</span> <span class="k">as</span> <span class="nn">tl</span>
<span class="kn">from</span> <span class="nn">tensorly.decomposition</span> <span class="kn">import</span> <span class="n">non_negative_tucker</span><span class="p">,</span> <span class="n">non_negative_tucker_hals</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">from</span> <span class="nn">tensorly.metrics.regression</span> <span class="kn">import</span> <span class="n">RMSE</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</pre></div>
</div>
</section>
<section id="create-synthetic-tensor">
<h2>Create synthetic tensor</h2>
<p>There are several ways to create a tensor with non-negative entries in Tensorly.
Here we chose to generate a random tensor from the sequence of integers from
1 to 1000.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># tensor generation</span>
<span class="n">array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">40</span><span class="p">))</span>
<span class="n">tensor</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float&#39;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="non-negative-tucker">
<h2>Non-negative Tucker</h2>
<p>First, multiplicative update can be implemented as:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tic</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">tensor_mu</span><span class="p">,</span> <span class="n">error_mu</span> <span class="o">=</span> <span class="n">non_negative_tucker</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">n_iter_max</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">return_errors</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">tucker_reconstruction_mu</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">tucker_to_tensor</span><span class="p">(</span><span class="n">tensor_mu</span><span class="p">)</span>
<span class="n">time_mu</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">tic</span>
</pre></div>
</div>
<p>Here, we also compute the output tensor from the decomposed factors by using
the <code class="docutils literal notranslate"><span class="pre">tucker_to_tensor</span></code> function. The tensor <code class="docutils literal notranslate"><span class="pre">tucker_reconstruction_mu</span></code> is
therefore a low-rank non-negative approximation of the input tensor <code class="docutils literal notranslate"><span class="pre">tensor</span></code>.</p>
</section>
<section id="non-negative-tucker-with-hals-and-fista">
<h2>Non-negative Tucker with HALS and FISTA</h2>
<p>HALS algorithm with FISTA can be calculated as:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ticnew</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">tensor_hals_fista</span><span class="p">,</span> <span class="n">error_fista</span> <span class="o">=</span> <span class="n">non_negative_tucker_hals</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="n">algorithm</span><span class="o">=</span><span class="s1">&#39;fista&#39;</span><span class="p">,</span> <span class="n">return_errors</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">tucker_reconstruction_fista</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">tucker_to_tensor</span><span class="p">(</span><span class="n">tensor_hals_fista</span><span class="p">)</span>
<span class="n">time_fista</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">ticnew</span>
</pre></div>
</div>
</section>
<section id="non-negative-tucker-with-hals-and-active-set">
<h2>Non-negative Tucker with HALS and Active Set</h2>
<p>As a second option, HALS algorithm with Active Set can be called as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ticnew</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">tensor_hals_as</span><span class="p">,</span> <span class="n">error_as</span> <span class="o">=</span> <span class="n">non_negative_tucker_hals</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="n">algorithm</span><span class="o">=</span><span class="s1">&#39;active_set&#39;</span><span class="p">,</span> <span class="n">return_errors</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">tucker_reconstruction_as</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">tucker_to_tensor</span><span class="p">(</span><span class="n">tensor_hals_as</span><span class="p">)</span>
<span class="n">time_as</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">ticnew</span>
</pre></div>
</div>
</section>
<section id="comparison">
<h2>Comparison</h2>
<p>To compare the various methods, first we may look at each algorithm
processing time:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;time for tensorly nntucker:&#39;</span><span class="o">+</span><span class="s1">&#39; &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">time_mu</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;time for HALS with fista:&#39;</span><span class="o">+</span><span class="s1">&#39; &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">time_fista</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;time for HALS with as:&#39;</span><span class="o">+</span><span class="s1">&#39; &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">time_as</span><span class="p">)))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>time for tensorly nntucker: 0.11
time for HALS with fista: 1.55
time for HALS with as: 0.46
</pre></div>
</div>
<p>All algorithms should run with about the same number of iterations on our
example, so at first glance the MU algorithm is faster (i.e. has lower
per-iteration complexity). A second way to compare methods is to compute
the error between the output and input tensor. In Tensorly, there is a function
to compute Root Mean Square Error (RMSE):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;RMSE tensorly nntucker:&#39;</span><span class="o">+</span><span class="s1">&#39; &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">RMSE</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">tucker_reconstruction_mu</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;RMSE for hals with fista:&#39;</span><span class="o">+</span><span class="s1">&#39; &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">RMSE</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">tucker_reconstruction_fista</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;RMSE for hals with as:&#39;</span><span class="o">+</span><span class="s1">&#39; &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">RMSE</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">tucker_reconstruction_as</span><span class="p">)))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>RMSE tensorly nntucker: 283.2206425356867
RMSE for hals with fista: 276.6783887069506
RMSE for hals with as: 276.88083130841756
</pre></div>
</div>
<p>According to the RMSE results, HALS is better than the multiplicative update
with both FISTA and active set core update options. We can better appreciate
the difference in convergence speed on the following error per iteration plot:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">each_iteration</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">c</span><span class="p">,</span><span class="n">title</span><span class="p">):</span>
    <span class="n">fig</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">fig</span><span class="o">.</span><span class="n">get_figheight</span><span class="p">(),</span> <span class="n">forward</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">title</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;MU&#39;</span><span class="p">,</span> <span class="s1">&#39;HALS + Fista&#39;</span><span class="p">,</span> <span class="s1">&#39;HALS + AS&#39;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">)</span>


<span class="n">each_iteration</span><span class="p">(</span><span class="n">error_mu</span><span class="p">,</span> <span class="n">error_fista</span><span class="p">,</span> <span class="n">error_as</span><span class="p">,</span> <span class="s1">&#39;Error for each iteration&#39;</span><span class="p">)</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_plot_nn_tucker_001.png" srcset="../../_images/sphx_glr_plot_nn_tucker_001.png" alt="Error for each iteration" class = "sphx-glr-single-img"/><p>In conclusion, on this quick test, it appears that the HALS algorithm gives
much better results than the MU original Tensorly methods. Our recommendation
is to use HALS as a default, and only resort to MU in specific cases
(only encountered by expert users most likely). Besides, in this experiment
FISTA and active set give very similar results, however active set may last
longer when it is used with higher ranks according to our experience.
Therefore, we recommend to use FISTA with high rank decomposition.</p>
</section>
<section id="references">
<h2>References</h2>
<p>Gillis, N., &amp; Glineur, F. (2012). Accelerated multiplicative updates and
hierarchical ALS algorithms for nonnegative matrix factorization.
Neural computation, 24(4), 1085-1105. (Link)
&lt;<a class="reference external" href="https://direct.mit.edu/neco/article/24/4/1085/7755/Accelerated-Multiplicative-Updates-and">https://direct.mit.edu/neco/article/24/4/1085/7755/Accelerated-Multiplicative-Updates-and</a>&gt;</p>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  2.236 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-decomposition-plot-nn-tucker-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/5a995fc29a1b64970094cc40854ffae2/plot_nn_tucker.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_nn_tucker.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/cdde43113b9e6de785a08675bf643a4d/plot_nn_tucker.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_nn_tucker.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>


        </div>

		
        <nav class="pagination" role="navigation" aria-label="pagination">
    
    <a class="button is-medium pagination-previous" href="plot_image_compression.html" title="previous page" accesskey="p">
        <span class="icon">
            <i class="fa fa-arrow-circle-left"></i>
        </span>
        <span>Image compression via tensor decomposition</span>
    </a>
    
    
    <a class="button is-medium pagination-next" href="plot_nn_cp_hals.html" title="next page" accesskey="n">
        <span>Non-negative CP decomposition in Tensorly &gt;=0.6 </span>
        <span class="icon">
            <i class="fa fa-arrow-circle-right"></i>
        </span>
    </a>
    
</nav>

        

      </section>

        <footer class="footer">
    <div class="content has-text-centered">
        <div class="block">
          &copy; Copyright 2016 - 2021, TensorLy Developers.<br/>
        </div>
    </div>
  </footer>

    </div>

	
    
    <div class="column is-hidden-touch is-2-desktop is-one-fifth-widescreen" id="localtoc-column">

    <aside class="sticky-nav localtoc">  
        <div class="menu menu-list">
        <p class="menu-label">On this page</p>
        <ul>
<li><a class="reference internal" href="#">Non-negative Tucker decomposition in Tensorly &gt;=0.6</a><ul>
<li><a class="reference internal" href="#introduction">Introduction</a></li>
<li><a class="reference internal" href="#create-synthetic-tensor">Create synthetic tensor</a></li>
<li><a class="reference internal" href="#non-negative-tucker">Non-negative Tucker</a></li>
<li><a class="reference internal" href="#non-negative-tucker-with-hals-and-fista">Non-negative Tucker with HALS and FISTA</a></li>
<li><a class="reference internal" href="#non-negative-tucker-with-hals-and-active-set">Non-negative Tucker with HALS and Active Set</a></li>
<li><a class="reference internal" href="#comparison">Comparison</a></li>
<li><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
</ul>

        </div>
    </aside>
    </div>

    

  </div>
  </div>

  <!-- Include here scripts that need to be added after the page is loaded -->
  <script>
    function toggle_sidebar() {
        var element = document.getElementById("sidebar");
        var container = document.getElementById("column-container");
        var localtoccolumn = document.getElementById("localtoc-column");
        element.classList.toggle("hide-tablet");
        element.classList.toggle("is-hidden-mobile");
        container.classList.toggle("sidemenu-hidden");
        localtoccolumn.classList.toggle("is-one-fifth-widescreen");
        localtoccolumn.classList.toggle("is-2-desktop");
        localtoccolumn.classList.toggle("is-3-desktop");
    }
  </script> 



  </body>
</html>