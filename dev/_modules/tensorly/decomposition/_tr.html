<!DOCTYPE html>

<html lang="en" data-content_root="../../../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>tensorly.decomposition._tr &#8212; TensorLy: Tensor Learning in Python</title> 
<link rel="stylesheet" href="../../../_static/tensorly_style.css">
<link rel="apple-touch-icon" sizes="180x180" href="../../../_static/favicon/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="../../../_static/favicon/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="../../../_static/favicon/favicon-16x16.png">
<link rel="manifest" href="../../../_static/favicon/site.webmanifest">
<link rel="mask-icon" href="../../../_static/favicon/safari-pinned-tab.svg" color="#5bbad5">
<link rel="shortcut icon" href="../../../_static/favicon/favicon.ico">
<meta name="theme-color" content="#ffffff">

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../../_static/tensorly_style.css?v=a02e9698" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery.css?v=61a4c737" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery-rendered-html.css?v=1277b6f3" />

  
    <script src="../../../_static/documentation_options.js?v=ec16d22d"></script>
    <script src="../../../_static/doctools.js?v=888ff710"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
 <script src="../../../_static/navbar_burger.js"></script>
 <script defer src="https://use.fontawesome.com/releases/v5.14.0/js/all.js"></script>
 
<script async src="https://www.googletagmanager.com/gtag/js?id=G-3V91QCZR03"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-3V91QCZR03');
</script>
    <link rel="author" title="About these documents" href="../../../about.html" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">

  </head>
<body  class="has-navbar-fixed-top">

  <header>
    <navbar>
      <nav class="navbar top-navbar is-fixed-top has-shadow is-flex-wrap-wrap" role="navigation" aria-label="main top navigation">
        <div class="navbar-brand">
        

          <a class="navbar-item" href="../../../index.html">
            <img src="../../../_static/logo_tensorly.png" height="28">
          </a>
          <a class="navbar-item is-hidden-desktop" href="https://github.com/tensorly/tensorly" target="_blank">
              <span class="icon"><i class="fab fa-github"></i></span>
          </a>

          <a role="button" class="navbar-burger" data-target="top-nav-menu" aria-label="menu" aria-expanded="false">
            <span aria-hidden="true"></span>
            <span aria-hidden="true"></span>
            <span aria-hidden="true"></span>
          </a>

        </div>
        
        <div class="navbar-menu" id="top-nav-menu">
        

          <div class="navbar-start">
            
              <a class="navbar-item" href="../../../installation.html">
              Install
            </a>
              <a class="navbar-item" href="../../../user_guide/index.html">
              User Guide
            </a>
              <a class="navbar-item" href="../../../modules/api.html">
              API
            </a>
              <a class="navbar-item" href="../../../auto_examples/index.html">
              Examples
            </a>
              <a class="navbar-item" href="../../../about.html">
              About Us
            </a>
            <div class="navbar-item has-dropdown is-hoverable is-boxed">
              <a class="navbar-link">
                Ecosystem
              </a>
              <div class="navbar-dropdown top-navbar">
                <a class="navbar-item" href="http://tensorly.org/torch" target="_blank">
                  TensorLy-Torch
                </a>
                <a class="navbar-item" href="http://tensorly.org/quantum" target="_blank">
                  TensorLy-Quantum
                </a>
                <a class="navbar-item" href="http://tensorly.org/viz" target="_blank">
                  TensorLy-Viz
                </a>
                <a class="navbar-item" href="https://github.com/JeanKossaifi/tensorly-notebooks" target="_blank">
                  Notebooks
                </a>
              </div>
            </div>
          </div>
        
          <div class="navbar-end">
            <div class="navbar-item">
            
            <a class="button is-hidden-touch is-dark" href="https://github.com/tensorly/tensorly" target="_blank">
              <span class="icon-text">
                <span class="icon is-large">
                  <i class="fab fa-github"></i>
                </span>
                <span>Github</span>
              </span>
            </a>

            </div> 
          </div> 
        </div> 

      </nav>
      
    </navbar>
  </header>


  <div id="column-container">
  <div class="columns is-mobile is-centered">
	
  

  <div class="column main-column">

    
    <div class="main-section">

      
      

      <div class="container content main-content">
        
  <h1>Source code for tensorly.decomposition._tr</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">tensorly</span> <span class="k">as</span> <span class="nn">tl</span>
<span class="kn">from</span> <span class="nn">._base_decomposition</span> <span class="kn">import</span> <span class="n">DecompositionMixin</span>
<span class="kn">from</span> <span class="nn">..base</span> <span class="kn">import</span> <span class="n">matricize</span>
<span class="kn">from</span> <span class="nn">..tr_tensor</span> <span class="kn">import</span> <span class="n">validate_tr_rank</span><span class="p">,</span> <span class="n">TRTensor</span>
<span class="kn">from</span> <span class="nn">..tenalg.svd</span> <span class="kn">import</span> <span class="n">svd_interface</span>


<div class="viewcode-block" id="tensor_ring">
<a class="viewcode-back" href="../../../modules/generated/tensorly.decomposition.tensor_ring.html#tensorly.decomposition.tensor_ring">[docs]</a>
<span class="k">def</span> <span class="nf">tensor_ring</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">svd</span><span class="o">=</span><span class="s2">&quot;truncated_svd&quot;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Tensor Ring decomposition via recursive SVD</span>

<span class="sd">        Decomposes `input_tensor` into a sequence of order-3 tensors (factors) [1]_.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    input_tensor : tensorly.tensor</span>
<span class="sd">    rank : Union[int, List[int]]</span>
<span class="sd">            maximum allowable TR rank of the factors</span>
<span class="sd">            if int, then this is the same for all the factors</span>
<span class="sd">            if int list, then rank[k] is the rank of the kth factor</span>
<span class="sd">    mode : int, default is 0</span>
<span class="sd">            index of the first factor to compute</span>
<span class="sd">    svd : str, default is &#39;truncated_svd&#39;</span>
<span class="sd">        function to use to compute the SVD, acceptable values in tensorly.SVD_FUNS</span>
<span class="sd">    verbose : boolean, optional</span>
<span class="sd">            level of verbosity</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    factors : TR factors</span>
<span class="sd">              order-3 tensors of the TR decomposition</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] Qibin Zhao et al. &quot;Tensor Ring Decomposition&quot; arXiv preprint arXiv:1606.05535, (2016).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">rank</span> <span class="o">=</span> <span class="n">validate_tr_rank</span><span class="p">(</span><span class="n">tl</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">),</span> <span class="n">rank</span><span class="o">=</span><span class="n">rank</span><span class="p">)</span>
    <span class="n">n_dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

    <span class="c1"># Change order</span>
    <span class="k">if</span> <span class="n">mode</span><span class="p">:</span>
        <span class="n">order</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">mode</span><span class="p">,</span> <span class="n">n_dim</span><span class="p">))</span> <span class="o">+</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">mode</span><span class="p">))</span>
        <span class="n">input_tensor</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">order</span><span class="p">)</span>
        <span class="n">rank</span> <span class="o">=</span> <span class="n">rank</span><span class="p">[</span><span class="n">mode</span><span class="p">:]</span> <span class="o">+</span> <span class="n">rank</span><span class="p">[:</span><span class="n">mode</span><span class="p">]</span>

    <span class="n">tensor_size</span> <span class="o">=</span> <span class="n">input_tensor</span><span class="o">.</span><span class="n">shape</span>

    <span class="n">factors</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">n_dim</span>

    <span class="c1"># Getting the first factor</span>
    <span class="n">unfolding</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="p">(</span><span class="n">tensor_size</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>

    <span class="n">n_row</span><span class="p">,</span> <span class="n">n_column</span> <span class="o">=</span> <span class="n">unfolding</span><span class="o">.</span><span class="n">shape</span>
    <span class="k">if</span> <span class="n">rank</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">rank</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="nb">min</span><span class="p">(</span><span class="n">n_row</span><span class="p">,</span> <span class="n">n_column</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;rank[</span><span class="si">{</span><span class="n">mode</span><span class="si">}</span><span class="s2">] * rank[</span><span class="si">{</span><span class="n">mode</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">] = </span><span class="si">{</span><span class="n">rank</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">rank</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2"> is larger than &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;first matricization dimension </span><span class="si">{</span><span class="n">n_row</span><span class="si">}</span><span class="s2">Ã—</span><span class="si">{</span><span class="n">n_column</span><span class="si">}</span><span class="s2">.</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="s2">&quot;Failed to compute first factor with specified rank. &quot;</span>
            <span class="s2">&quot;Reduce specified ranks or change first matricization `mode`.&quot;</span>
        <span class="p">)</span>

    <span class="c1"># SVD of unfolding matrix</span>
    <span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">V</span> <span class="o">=</span> <span class="n">svd_interface</span><span class="p">(</span><span class="n">unfolding</span><span class="p">,</span> <span class="n">n_eigenvecs</span><span class="o">=</span><span class="n">rank</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">rank</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">method</span><span class="o">=</span><span class="n">svd</span><span class="p">)</span>

    <span class="c1"># Get first TR factor</span>
    <span class="n">factor</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">U</span><span class="p">,</span> <span class="p">(</span><span class="n">tensor_size</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">rank</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">rank</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">factors</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">factor</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">verbose</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;TR factor &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">mode</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; computed with shape &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">factor</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>

    <span class="c1"># Get new unfolding matrix for the remaining factors</span>
    <span class="n">unfolding</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">S</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="o">*</span> <span class="n">V</span>
    <span class="n">unfolding</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">unfolding</span><span class="p">,</span> <span class="p">(</span><span class="n">rank</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">rank</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">unfolding</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">unfolding</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>

    <span class="c1"># Getting the TR factors up to n_dim - 1</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_dim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="c1"># Reshape the unfolding matrix of the remaining factors</span>
        <span class="n">n_row</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">rank</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">tensor_size</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>
        <span class="n">unfolding</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">unfolding</span><span class="p">,</span> <span class="p">(</span><span class="n">n_row</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>

        <span class="c1"># SVD of unfolding matrix</span>
        <span class="n">n_row</span><span class="p">,</span> <span class="n">n_column</span> <span class="o">=</span> <span class="n">unfolding</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">current_rank</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">n_row</span><span class="p">,</span> <span class="n">n_column</span><span class="p">,</span> <span class="n">rank</span><span class="p">[</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span>
        <span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">V</span> <span class="o">=</span> <span class="n">svd_interface</span><span class="p">(</span><span class="n">unfolding</span><span class="p">,</span> <span class="n">n_eigenvecs</span><span class="o">=</span><span class="n">current_rank</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="n">svd</span><span class="p">)</span>
        <span class="n">rank</span><span class="p">[</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">current_rank</span>

        <span class="c1"># Get kth TR factor</span>
        <span class="n">factors</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">U</span><span class="p">,</span> <span class="p">(</span><span class="n">rank</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">tensor_size</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">rank</span><span class="p">[</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]))</span>

        <span class="k">if</span> <span class="n">verbose</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="s2">&quot;TR factor &quot;</span>
                <span class="o">+</span> <span class="nb">str</span><span class="p">((</span><span class="n">mode</span> <span class="o">+</span> <span class="n">k</span><span class="p">)</span> <span class="o">%</span> <span class="n">n_dim</span><span class="p">)</span>
                <span class="o">+</span> <span class="s2">&quot; computed with shape &quot;</span>
                <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">factors</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
            <span class="p">)</span>

        <span class="c1"># Get new unfolding matrix for the remaining factors</span>
        <span class="n">unfolding</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">S</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="o">*</span> <span class="n">V</span>

    <span class="c1"># Getting the last factor</span>
    <span class="n">prev_rank</span> <span class="o">=</span> <span class="n">unfolding</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">factors</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">unfolding</span><span class="p">,</span> <span class="p">(</span><span class="n">prev_rank</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">rank</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>

    <span class="k">if</span> <span class="n">verbose</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span>
            <span class="s2">&quot;TR factor &quot;</span>
            <span class="o">+</span> <span class="nb">str</span><span class="p">((</span><span class="n">mode</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">n_dim</span><span class="p">)</span>
            <span class="o">+</span> <span class="s2">&quot; computed with shape &quot;</span>
            <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">factors</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="c1"># Reorder factors to match input</span>
    <span class="k">if</span> <span class="n">mode</span><span class="p">:</span>
        <span class="n">factors</span> <span class="o">=</span> <span class="n">factors</span><span class="p">[</span><span class="o">-</span><span class="n">mode</span><span class="p">:]</span> <span class="o">+</span> <span class="n">factors</span><span class="p">[:</span><span class="o">-</span><span class="n">mode</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">TRTensor</span><span class="p">(</span><span class="n">factors</span><span class="p">)</span></div>



<span class="k">def</span> <span class="nf">tensor_ring_als</span><span class="p">(</span>
    <span class="n">tensor</span><span class="p">,</span>
    <span class="n">rank</span><span class="p">,</span>
    <span class="n">ls_solve</span><span class="o">=</span><span class="s2">&quot;lstsq&quot;</span><span class="p">,</span>
    <span class="n">n_iter_max</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">tol</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">callback</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Tensor ring decomposition via alternating least squares (ALS)</span>

<span class="sd">    Computes a rank-`rank` tensor ring decomposition of `tensor` using ALS. The</span>
<span class="sd">    implementation roughly follows Algorithm 2 in [1]_.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    tensor : ndarray</span>
<span class="sd">    rank : Union[int, List[int]]</span>
<span class="sd">        The rank of the decomposition. If `rank` is an int, then all ranks will be the</span>
<span class="sd">        same and equal to `rank`. If `rank` is a list, then the i-th core will be of</span>
<span class="sd">        size rank[i]-by-shape[i]-by-rank[i+1], where shape[i] is the dimension of the</span>
<span class="sd">        i-th mode of `tensor`.</span>
<span class="sd">    ls_solve : {&quot;lstsq&quot;, &quot;normal_eq&quot;}, default is &quot;lstsq&quot;</span>
<span class="sd">        When equal to &quot;lstsq&quot;, the least squares problems are solved as overdetermined</span>
<span class="sd">        systems of equations using tl.lstsq. When equal to &quot;normal_eq&quot;, a normal</span>
<span class="sd">        equation formulation is used instead together with tl.solve. This latter</span>
<span class="sd">        approach is expected to yield poorer accuracy due to numerical issuse with the</span>
<span class="sd">        normal equations.</span>
<span class="sd">    n_iter_max : int, default is 100</span>
<span class="sd">        Maximum number of ALS iterations.</span>
<span class="sd">    tol : float, default 1e-6</span>
<span class="sd">        The algorithm is terminated when the change in the relative reconstruction error</span>
<span class="sd">        is less than `tol`.</span>
<span class="sd">    random_state : {None, int, np.random.RandomState}</span>
<span class="sd">        Used to set the random seed in the algorithm.</span>
<span class="sd">    verbose : bool, default False</span>
<span class="sd">        If True, the algorithm will make some additional print outs.</span>
<span class="sd">    callback : {None, Callable[[tl.tr_tensor.TRTensor, float], {None, bool}]}, default None</span>
<span class="sd">        A callback function which can be used for, e.g., logging the per-iteration</span>
<span class="sd">        error. Such a function takes two inputs: A tensor ring decomposition and a float</span>
<span class="sd">        which indicates the relative reconstruction error between `tensor` and the</span>
<span class="sd">        inputted TRTensor. It can return a bool which can be used to control when the</span>
<span class="sd">        ALS algorithm terminates.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    tr_decomp : tl.tr_tensor.TRTensor</span>
<span class="sd">        The tensor ring decomposition computed by the algorithm.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] Q. Zhao, G. Zhou, S. Xie, L. Zhang, A. Cichocki, &quot;Tensor Ring Decomposition&quot;,</span>
<span class="sd">           arXiv:1606.05535, 2016.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">shape</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>
    <span class="n">rank</span> <span class="o">=</span> <span class="n">validate_tr_rank</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="n">rank</span><span class="p">)</span>
    <span class="n">n_dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">check_random_state</span><span class="p">(</span><span class="n">random_state</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">tol</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">callback</span><span class="p">:</span>
        <span class="n">tensor_norm</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>
    <span class="n">valid_ls_solve</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;lstsq&quot;</span><span class="p">,</span> <span class="s2">&quot;normal_eq&quot;</span><span class="p">}</span>
    <span class="k">if</span> <span class="n">ls_solve</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">valid_ls_solve</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Invalid value provided for ls_solve. It must be in </span><span class="si">{</span><span class="n">valid_ls_solve</span><span class="si">}</span><span class="s2">.&quot;</span>
        <span class="p">)</span>

    <span class="c1"># Randomly initialize decomposition cores</span>
    <span class="n">tr_decomp</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random_tr</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="p">,</span> <span class="o">**</span><span class="n">tl</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">tensor</span><span class="p">))</span>

    <span class="c1"># Run callback function if provided</span>
    <span class="k">if</span> <span class="n">callback</span><span class="p">:</span>
        <span class="n">rel_error</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">tl</span><span class="o">.</span><span class="n">tr_to_tensor</span><span class="p">(</span><span class="n">tr_decomp</span><span class="p">)</span> <span class="o">-</span> <span class="n">tensor</span><span class="p">)</span> <span class="o">/</span> <span class="n">tensor_norm</span>
        <span class="n">callback</span><span class="p">(</span><span class="n">tr_decomp</span><span class="p">,</span> <span class="n">rel_error</span><span class="p">)</span>

    <span class="c1"># Main loop</span>
    <span class="n">rec_errors</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="nb">iter</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_iter_max</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">dim</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_dim</span><span class="p">):</span>
            <span class="c1"># Compute appropriate transposed unfolding of tensor</span>
            <span class="n">tensor_unf</span> <span class="o">=</span> <span class="n">matricize</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="p">[</span><span class="n">n</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_dim</span><span class="p">)</span> <span class="k">if</span> <span class="n">n</span> <span class="o">!=</span> <span class="n">dim</span><span class="p">],</span> <span class="p">[</span><span class="n">dim</span><span class="p">])</span>

            <span class="c1"># Compute design matrix</span>
            <span class="n">subchain_tensor</span> <span class="o">=</span> <span class="n">tr_decomp</span><span class="p">[(</span><span class="n">dim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">n_dim</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_dim</span><span class="p">):</span>
                <span class="n">subchain_tensor</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">tensordot</span><span class="p">(</span>
                    <span class="n">subchain_tensor</span><span class="p">,</span> <span class="n">tr_decomp</span><span class="p">[(</span><span class="n">dim</span> <span class="o">+</span> <span class="n">j</span><span class="p">)</span> <span class="o">%</span> <span class="n">n_dim</span><span class="p">],</span> <span class="n">axes</span><span class="o">=</span><span class="mi">1</span>
                <span class="p">)</span>
            <span class="n">tr_idx</span> <span class="o">=</span> <span class="p">(</span>
                <span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="n">n_dim</span> <span class="o">-</span> <span class="n">dim</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">dim</span><span class="p">)]</span>
                <span class="o">+</span> <span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_dim</span> <span class="o">-</span> <span class="n">dim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)]</span>
                <span class="o">+</span> <span class="p">[</span><span class="n">n_dim</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
            <span class="p">)</span>
            <span class="n">subchain_tensor</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">subchain_tensor</span><span class="p">,</span> <span class="n">tr_idx</span><span class="p">)</span>
            <span class="n">design_mat</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">subchain_tensor</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">rank</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">*</span> <span class="n">rank</span><span class="p">[</span><span class="n">dim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]))</span>

            <span class="k">if</span> <span class="n">ls_solve</span> <span class="o">==</span> <span class="s2">&quot;lstsq&quot;</span><span class="p">:</span>
                <span class="c1"># Solve least squares problem directly</span>
                <span class="n">sol</span><span class="p">,</span> <span class="o">*</span><span class="n">_</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">lstsq</span><span class="p">(</span><span class="n">design_mat</span><span class="p">,</span> <span class="n">tensor_unf</span><span class="p">)</span>

            <span class="k">elif</span> <span class="n">ls_solve</span> <span class="o">==</span> <span class="s2">&quot;normal_eq&quot;</span><span class="p">:</span>
                <span class="c1"># Solve least squares problem via normal equations</span>
                <span class="n">design_mat_tr</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">design_mat</span><span class="p">)</span>
                <span class="n">gram_mat</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">design_mat_tr</span><span class="p">,</span> <span class="n">design_mat</span><span class="p">)</span>
                <span class="n">rhs_mat</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">design_mat_tr</span><span class="p">,</span> <span class="n">tensor_unf</span><span class="p">)</span>
                <span class="n">sol</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">gram_mat</span><span class="p">,</span> <span class="n">rhs_mat</span><span class="p">)</span>

            <span class="c1"># Update core</span>
            <span class="n">tr_decomp</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span>
                <span class="n">tl</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">sol</span><span class="p">,</span> <span class="p">(</span><span class="n">rank</span><span class="p">[</span><span class="n">dim</span><span class="p">],</span> <span class="n">rank</span><span class="p">[</span><span class="n">dim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span> <span class="n">shape</span><span class="p">[</span><span class="n">dim</span><span class="p">])),</span>
                <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
            <span class="p">)</span>

        <span class="c1"># Compute relative error if necessary</span>
        <span class="k">if</span> <span class="n">tol</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">callback</span><span class="p">:</span>
            <span class="n">error</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">tl</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">design_mat</span><span class="p">,</span> <span class="n">sol</span><span class="p">)</span> <span class="o">-</span> <span class="n">tensor_unf</span><span class="p">)</span>
            <span class="n">rel_error</span> <span class="o">=</span> <span class="n">error</span> <span class="o">/</span> <span class="n">tensor_norm</span>
            <span class="n">rec_errors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rel_error</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">iter</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">rel_error_decrease</span> <span class="o">=</span> <span class="n">rec_errors</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">-</span> <span class="n">rec_errors</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">iter</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Iteration </span><span class="si">{</span><span class="nb">iter</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2"> finished. Reconstruction error: </span><span class="si">{</span><span class="n">rel_error</span><span class="si">}</span><span class="s2">, decrease = </span><span class="si">{</span><span class="n">rel_error_decrease</span><span class="si">}</span><span class="s2">, unnormalized = </span><span class="si">{</span><span class="n">error</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Iteration </span><span class="si">{</span><span class="nb">iter</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2"> finished. Reconstruction error: </span><span class="si">{</span><span class="n">rel_error</span><span class="si">}</span><span class="s2">, unnormalized = </span><span class="si">{</span><span class="n">error</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="p">)</span>
        <span class="k">elif</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Iteration </span><span class="si">{</span><span class="nb">iter</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2"> finished.&quot;</span><span class="p">)</span>

        <span class="c1"># Run callback function if provided</span>
        <span class="k">if</span> <span class="n">callback</span><span class="p">:</span>
            <span class="n">callback_retVal</span> <span class="o">=</span> <span class="n">callback</span><span class="p">(</span><span class="n">tr_decomp</span><span class="p">,</span> <span class="n">rel_error</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">callback_retVal</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Received True from callback function. Exiting.&quot;</span><span class="p">)</span>
                <span class="k">break</span>

        <span class="c1"># Check convergence</span>
        <span class="k">if</span> <span class="n">tol</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="nb">iter</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">rel_error_decrease</span> <span class="o">&lt;</span> <span class="n">tol</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;tensor_ring_als converged after </span><span class="si">{</span><span class="nb">iter</span><span class="si">}</span><span class="s2"> iterations.&quot;</span><span class="p">)</span>
                <span class="k">break</span>

    <span class="k">return</span> <span class="n">tr_decomp</span>


<div class="viewcode-block" id="TensorRing">
<a class="viewcode-back" href="../../../modules/generated/tensorly.decomposition.TensorRing.html#tensorly.decomposition.TensorRing">[docs]</a>
<span class="k">class</span> <span class="nc">TensorRing</span><span class="p">(</span><span class="n">DecompositionMixin</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Tensor Ring decomposition via recursive SVD</span>

<span class="sd">        Decomposes `input_tensor` into a sequence of order-3 tensors (factors) [1]_.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    input_tensor : tensorly.tensor</span>
<span class="sd">    rank : Union[int, List[int]]</span>
<span class="sd">            maximum allowable TR rank of the factors</span>
<span class="sd">            if int, then this is the same for all the factors</span>
<span class="sd">            if int list, then rank[k] is the rank of the kth factor</span>
<span class="sd">    mode : int, default is 0</span>
<span class="sd">            index of the first factor to compute</span>
<span class="sd">    svd : str, default is &#39;truncated_svd&#39;</span>
<span class="sd">        function to use to compute the SVD, acceptable values in tensorly.SVD_FUNS</span>
<span class="sd">    verbose : boolean, optional</span>
<span class="sd">            level of verbosity</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    factors : TR factors</span>
<span class="sd">              order-3 tensors of the TR decomposition</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] Qibin Zhao et al. &quot;Tensor Ring Decomposition&quot; arXiv preprint arXiv:1606.05535, (2016).</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">svd</span><span class="o">=</span><span class="s2">&quot;truncated_svd&quot;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">=</span> <span class="n">rank</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">mode</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">svd</span> <span class="o">=</span> <span class="n">svd</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>

    <span class="k">def</span> <span class="nf">fit_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decomposition_</span> <span class="o">=</span> <span class="n">tensor_ring</span><span class="p">(</span>
            <span class="n">tensor</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">rank</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">mode</span><span class="p">,</span> <span class="n">svd</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">svd</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">decomposition_</span></div>



<span class="k">class</span> <span class="nc">TensorRingALS</span><span class="p">(</span><span class="n">DecompositionMixin</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A class wrapper for the tensor_ring_als function</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    rank : Union[int, List[int]]</span>
<span class="sd">        The rank of the decomposition. If `rank` is an int, then all ranks will be the</span>
<span class="sd">        same and equal to `rank`. If `rank` is a list, then the i-th core will be of</span>
<span class="sd">        size rank[i]-by-shape[i]-by-rank[i+1], where shape[i] is the dimension of the</span>
<span class="sd">        i-th mode of `tensor`.</span>
<span class="sd">    ls_solve : {&quot;lstsq&quot;, &quot;normal_eq&quot;}</span>
<span class="sd">        When equal to &quot;lstsq&quot;, the least squares problems are solved as overdetermined</span>
<span class="sd">        systems of equations using tl.lstsq. When equal to &quot;normal_eq&quot;, a normal</span>
<span class="sd">        equation formulation is used instead together with tl.solve. This latter</span>
<span class="sd">        approach is expected to yield poorer accuracy due to numerical issuse with the</span>
<span class="sd">        normal equations.</span>
<span class="sd">    n_iter_max : int</span>
<span class="sd">        Maximum number of ALS iterations.</span>
<span class="sd">    tol : float</span>
<span class="sd">        The algorithm is terminated when the change in the relative reconstruction error</span>
<span class="sd">        is less than `tol`.</span>
<span class="sd">    random_state : {None, int, np.random.RandomState}</span>
<span class="sd">        Used to set the random seed in the algorithm.</span>
<span class="sd">    verbose : bool</span>
<span class="sd">        If True, the algorithm will make some additional print outs.</span>
<span class="sd">    callback : {None, Callable[[tl.tr_tensor.TRTensor, float], {None, bool}]}</span>
<span class="sd">        A callback function which can be used for, e.g., logging the per-iteration</span>
<span class="sd">        error. Such a function takes two inputs: A tensor ring decomposition and a float</span>
<span class="sd">        which indicates the relative reconstruction error between `tensor` and the</span>
<span class="sd">        inputted TRTensor. It can return a bool which can be used to control when the</span>
<span class="sd">        ALS algorithm terminates.</span>

<span class="sd">    Methods</span>
<span class="sd">    -------</span>
<span class="sd">    fit_transformation(tensor)</span>
<span class="sd">        Computes the decomposition of `tensor`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">rank</span><span class="p">,</span>
        <span class="n">ls_solve</span><span class="o">=</span><span class="s2">&quot;lstsq&quot;</span><span class="p">,</span>
        <span class="n">n_iter_max</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">tol</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span>
        <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">callback</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        rank : Union[int, List[int]]</span>
<span class="sd">            The rank of the decomposition. If `rank` is an int, then all ranks will be the</span>
<span class="sd">            same and equal to `rank`. If `rank` is a list, then the i-th core will be of</span>
<span class="sd">            size rank[i]-by-shape[i]-by-rank[i+1], where shape[i] is the dimension of the</span>
<span class="sd">            i-th mode of `tensor`.</span>
<span class="sd">        ls_solve : {&quot;lstsq&quot;, &quot;normal_eq&quot;}, default is &quot;lstsq&quot;</span>
<span class="sd">            When equal to &quot;lstsq&quot;, the least squares problems are solved as overdetermined</span>
<span class="sd">            systems of equations using tl.lstsq. When equal to &quot;normal_eq&quot;, a normal</span>
<span class="sd">            equation formulation is used instead together with tl.solve. This latter</span>
<span class="sd">            approach is expected to yield poorer accuracy due to numerical issuse with the</span>
<span class="sd">            normal equations.</span>
<span class="sd">        n_iter_max : int, default is 100</span>
<span class="sd">            Maximum number of ALS iterations.</span>
<span class="sd">        tol : float, default 1e-6</span>
<span class="sd">            The algorithm is terminated when the change in the relative reconstruction error</span>
<span class="sd">            is less than `tol`.</span>
<span class="sd">        random_state : {None, int, np.random.RandomState}</span>
<span class="sd">            Used to set the random seed in the algorithm.</span>
<span class="sd">        verbose : bool, default False</span>
<span class="sd">            If True, the algorithm will make some additional print outs.</span>
<span class="sd">        callback : {None, Callable[[tl.tr_tensor.TRTensor, float], {None, bool}]}, default None</span>
<span class="sd">            A callback function which can be used for, e.g., logging the per-iteration</span>
<span class="sd">            error. Such a function takes two inputs: A tensor ring decomposition and a float</span>
<span class="sd">            which indicates the relative reconstruction error between `tensor` and the</span>
<span class="sd">            inputted TRTensor. It can return a bool which can be used to control when the</span>
<span class="sd">            ALS algorithm terminates.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">=</span> <span class="n">rank</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ls_solve</span> <span class="o">=</span> <span class="n">ls_solve</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_iter_max</span> <span class="o">=</span> <span class="n">n_iter_max</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tol</span> <span class="o">=</span> <span class="n">tol</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">callback</span> <span class="o">=</span> <span class="n">callback</span>

    <span class="k">def</span> <span class="nf">fit_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Computes the decomposition of `tensor`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        tensor : ndarray</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        decomposition_ : tl.tr_tensor.TRTensor</span>
<span class="sd">            The tensor ring decomposition computed by the algorithm.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">tr_decomp</span> <span class="o">=</span> <span class="n">tensor_ring_als</span><span class="p">(</span>
            <span class="n">tensor</span><span class="p">,</span>
            <span class="n">rank</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">rank</span><span class="p">,</span>
            <span class="n">ls_solve</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ls_solve</span><span class="p">,</span>
            <span class="n">n_iter_max</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iter_max</span><span class="p">,</span>
            <span class="n">tol</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tol</span><span class="p">,</span>
            <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span>
            <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">callback</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decomposition_</span> <span class="o">=</span> <span class="n">tr_decomp</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">decomposition_</span>
</pre></div>

      </div>

      

        <footer class="footer">
    <div class="content has-text-centered">
        <div class="block">
          &copy; Copyright 2016 - 2023, TensorLy Developers.<br/>
        </div>
    </div>
  </footer>

    </div>

  </div>  

	

  </div>  
  </div> 

  
  <script>
    function toggle_sidebar() {
        var element = document.getElementById("sidebar");
        var container = document.getElementById("column-container");
        var localtoccolumn = document.getElementById("localtoc-column");
        element.classList.toggle("hide-tablet");
        element.classList.toggle("is-hidden-mobile");
        container.classList.toggle("sidemenu-hidden");
        localtoccolumn.classList.toggle("is-one-fifth-widescreen");
        localtoccolumn.classList.toggle("is-2-desktop");
        localtoccolumn.classList.toggle("is-3-desktop");
    }
  </script> 



  </body>
</html>