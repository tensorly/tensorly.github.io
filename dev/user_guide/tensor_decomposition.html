
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>4. Tensor decomposition &#8212; TensorLy: Tensor Learning in Python</title> 
<link rel="stylesheet" href="../_static/tensorly_style.css">
<link rel="apple-touch-icon" sizes="180x180" href="../_static/favicon/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="../_static/favicon/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="../_static/favicon/favicon-16x16.png">
<link rel="manifest" href="../_static/favicon/site.webmanifest">
<link rel="mask-icon" href="../_static/favicon/safari-pinned-tab.svg" color="#5bbad5">
<link rel="shortcut icon" href="../_static/favicon/favicon.ico">
<meta name="theme-color" content="#ffffff">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/tensorly_style.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-rendered-html.css" />

  
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
 <script src="../_static/navbar_burger.js"></script>
 <script defer src="https://use.fontawesome.com/releases/v5.14.0/js/all.js"></script>
 
<script async src="https://www.googletagmanager.com/gtag/js?id=G-3V91QCZR03"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-3V91QCZR03');
</script>
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="5. Tensor regression" href="tensor_regression.html" />
    <link rel="prev" title="3. Tensor basics" href="tensor_basics.html" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">

  </head>
<body  class="has-navbar-fixed-top">

  <header>
    <navbar>
      <nav class="navbar top-navbar is-fixed-top has-shadow is-flex-wrap-wrap" role="navigation" aria-label="main top navigation">
        <div class="navbar-brand">
        <!-- Always displayed, last item has to be navbar-burger -->

          <a class="navbar-item" href="../index.html">
            <img src="../_static/logo_tensorly.png" height="28">
          </a>

          <!-- <a class="navbar-item is-hidden-desktop" href="../index.html">
            <span class="icon"><i class="fa fa-home" aria-hidden="true"></i></span>
          </a> -->
          <a class="navbar-item is-hidden-desktop" href="https://github.com/tensorly/tensorly" target="_blank">
              <span class="icon"><i class="fab fa-github"></i></span>
          </a>

          <a role="button" class="navbar-burger" data-target="top-nav-menu" aria-label="menu" aria-expanded="false">
            <span aria-hidden="true"></span>
            <span aria-hidden="true"></span>
            <span aria-hidden="true"></span>
          </a>

        </div>
        
        <div class="navbar-menu" id="top-nav-menu">
        <!-- only on larger displays (> 1024px) -->

          <div class="navbar-start">
          <!-- RIGHT -->
            <a class="navbar-item" href="../installation.html">
              Install
            </a>
            <a class="navbar-item" href="index.html">
              User Guide
            </a>
            <a class="navbar-item" href="../modules/api.html">
              API
            </a>
            <a class="navbar-item" href="../auto_examples/index.html">
              Examples
            </a>
            <a class="navbar-item" href="../about.html">
              About Us
            </a>
            <a class="navbar-item" href="https://github.com/JeanKossaifi/tensorly-notebooks" target="_blank">
              Notebooks
            </a>

          </div>
        
          <div class="navbar-end">
            <div class="navbar-item">
            <!-- LEFT -->

            <!-- <a class="navbar-item is-hidden-touch" href="../index.html">
              <span class="icon-text">
                <span class="icon">
                  <i class="fa fa-home"></i>
                </span>
                <span>Home</span>
              </span>
              <span class="icon"><i class="fa fa-home" aria-hidden="true"></i></span>
            </a> -->
            <a class="button is-hidden-touch is-dark" href="https://github.com/tensorly/tensorly" target="_blank">
              <span class="icon-text">
                <span class="icon is-large">
                  <i class="fab fa-github"></i>
                </span>
                <span>Github</span>
              </span>
                <!-- <span class="icon"><i class="fab fa-github"></i></span> -->
            </a>

            </div> <!-- navbar item -->
          </div> <!-- navbar end -->
        </div> <!-- only large items -->

      </nav>
      
    </navbar>
  </header>

  <div id="column-container">
  <div class="columns is-mobile is-centered">
	
      <div class="column is-10-mobile is-one-third-tablet is-3-desktop is-hidden-mobile" id="sidebar">
    <!-- Side menu  -->
    <aside class="sticky-nav sidebar-menu">
<div class="sidebar-search">
  <form class="field" id="searchbox" role="search" action="../search.html" method="get">
    <!-- <label class="label" id="searchlabel">Quick search</label> -->
    <div class="field has-addons">
      <div class="control is-expanded">
        <input class="input" type="text" placeholder="Search in TensorLy" name="q" aria-labelledby="searchlabel">
      </div>
      <div class="control">
        <input class="button is-info" type="submit" value="Go" />
      </div>
    </div>
  </form>
  <script>$('#searchbox').show(0);</script>
  <script>
  $(document).ready(function() {
    Document.highlightSearchWords = function() {
      var params = $.getQueryParameters();
      var terms = (params.highlight) ? params.highlight[0].split(/\s+/) : [];
      if (terms.length) {
        var body = $('div.body');
        if (!body.length) {
          body = $('body');
        }
        window.setTimeout(function() {
          $.each(terms, function() {
            body.highlightText(this.toLowerCase(), 'highlighted');
          });
        }, 10);
        $('<p class="highlight-link"><a href="javascript:Documentation.' +
          'hideSearchWords()">' + _('Hide All')
          + '<span class="tag is-delete"></span>'
          + '</a></p>')
            .appendTo($('#searchbox'));
      }
    };
  });
  </script>
</div>
      
      <div class="sidebar-menu-toc">
      <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installing tensorly</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">User guide</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="quickstart.html">1. Quick-Start</a></li>
<li class="toctree-l2"><a class="reference internal" href="backend.html">2. TensorLy’s backend system</a></li>
<li class="toctree-l2"><a class="reference internal" href="tensor_basics.html">3. Tensor basics</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">4. Tensor decomposition</a></li>
<li class="toctree-l2"><a class="reference internal" href="tensor_regression.html">5. Tensor regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="sparse_backend.html">6. Sparse Backend</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../modules/api.html">API reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_examples/index.html">Gallery of examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../development_guide/index.html">Development guide</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/JeanKossaifi/tensorly-notebooks">Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../about.html">About us</a></li>
</ul>
 
      </div>
    </aside>
  </div>
  

    <div class="column main-column">

      <!-- Main content  -->
      <section class="main-section">

        <!-- Toggle menu button -->
		
        <div class="side-menu-toggle">
          <button class="button" id="toggle-sidebar" onclick="toggle_sidebar()">
            <span class="icon"><i class="fa fa-bars" aria-hidden="true"></i></span>
            <span>menu</span> 
          </button>
        </div>
        

        <div class="content main-content">
          
  <section id="tensor-decomposition">
<h1><span class="section-number">4. </span>Tensor decomposition</h1>
<p>One of the greatest features of tensors is that they can be represented compactly in decomposed forms and we have powerful methods with guarantees to obtain these decompositions.</p>
<p>In this tutorial we will go over these decomposed forms and how to perform tensor decomposition.
Refer to <a class="footnote-reference brackets" href="#id3" id="id1">1</a> for more information on tensor decomposition.</p>
<section id="cp-form-of-a-tensor">
<h2><span class="section-number">4.1. </span>CP form of a tensor</h2>
<p>The idea is to express the tensor as a sum of rank one tensors. That is, a sum of outer product of vectors.
Such representation can be obtained by applying Canonical Polyadic Decomposition (also known as CANDECOMP-PARAFAC, CP, or PARAFAC decomposition).</p>
<section id="candecomp-parafac-decomposition">
<h3><span class="section-number">4.1.1. </span>CANDECOMP-PARAFAC decomposition</h3>
<p>We demonstrate here how to perform a Canonical Polyadic Decomposition. A rank-r Parafac decomposes a tensor into a linear combination of r rank-1 tensors (See <a class="footnote-reference brackets" href="#id3" id="id2">1</a> for more details).</p>
<p>First, let’s create a second order tensor that is zero everywhere except in a swiss shape that is one.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">tensorly</span> <span class="k">as</span> <span class="nn">tl</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tensor</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span> <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">],</span>
<span class="go">                        [ 0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.],</span>
<span class="go">                        [ 0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.],</span>
<span class="go">                        [ 0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.],</span>
<span class="go">                        [ 0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.],</span>
<span class="go">                        [ 0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.],</span>
<span class="go">                        [ 0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.],</span>
<span class="go">                        [ 0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.],</span>
<span class="go">                        [ 0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.],</span>
<span class="go">                        [ 0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.],</span>
<span class="go">                        [ 0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.],</span>
<span class="go">                        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])</span>
</pre></div>
</div>
<p>We will now apply a rank-2 CANDECOMP-PARAFAC (<a class="reference internal" href="../modules/generated/tensorly.decomposition.parafac.html#tensorly.decomposition.parafac" title="tensorly.decomposition.parafac"><code class="xref py py-func docutils literal notranslate"><span class="pre">tensorly.decomposition.parafac</span></code></a>) decomposition on <cite>tensor</cite>
to decompose this into a cp tensor.</p>
<p>A Parafac decompositions expresses the tensor as a cp tensor that can be represented as a list of factors (matrices).
The <code class="xref py py-func docutils literal notranslate"><span class="pre">parafac</span></code> function therefore returns a list of factors.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tensorly.decomposition</span> <span class="kn">import</span> <span class="n">parafac</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">factors</span> <span class="o">=</span> <span class="n">parafac</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">len</span><span class="p">(</span><span class="n">factors</span><span class="p">)</span>
<span class="go">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">[</span><span class="n">f</span><span class="o">.</span><span class="n">shape</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">factors</span><span class="p">]</span>
<span class="go">[(12, 2), (12, 2)]</span>
</pre></div>
</div>
<p>From this <strong>cp tensor</strong> (presented as a list of matrices) you can reconstruct a full tensor:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">tl</span><span class="o">.</span><span class="n">cp_to_tensor</span><span class="p">(</span><span class="n">factors</span><span class="p">))</span>
<span class="go">[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]</span>
<span class="go"> [ 0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  0.  0.]</span>
<span class="go"> [ 0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  0.  0.]</span>
<span class="go"> [ 0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  0.  0.]</span>
<span class="go"> [ 0.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.]</span>
<span class="go"> [ 0.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.]</span>
<span class="go"> [ 0.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.]</span>
<span class="go"> [ 0.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.]</span>
<span class="go"> [ 0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  0.  0.]</span>
<span class="go"> [ 0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  0.  0.]</span>
<span class="go"> [ 0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  0.  0.]</span>
<span class="go"> [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]</span>
</pre></div>
</div>
</section>
</section>
<section id="tucker-form-of-a-tensor">
<h2><span class="section-number">4.2. </span>Tucker form of a tensor</h2>
<p>The Tucker decomposition can be seen as a generalisation of the CP decomposition: it decomposes the tensor into a small core tensor and factor matrices. CP can be seen as a Tucker decomposition with a super-diagonal core.</p>
<p>A tensor in its decomposed Tucker form is therefore nothing more than a core tensor with the same order as the original tensor and a list of projection matrices, one for each mode of the core tensor.</p>
<section id="tucker-decomposition">
<h3><span class="section-number">4.2.1. </span>Tucker decomposition</h3>
<p>Tucker (classical and non-negative) are available in TensorLy (<a class="reference internal" href="../modules/generated/tensorly.decomposition.tucker.html#tensorly.decomposition.tucker" title="tensorly.decomposition.tucker"><code class="xref py py-func docutils literal notranslate"><span class="pre">tensorly.decomposition.tucker</span></code></a> and <a class="reference internal" href="../modules/generated/tensorly.decomposition.non_negative_tucker.html#tensorly.decomposition.non_negative_tucker" title="tensorly.decomposition.non_negative_tucker"><code class="xref py py-func docutils literal notranslate"><span class="pre">tensorly.decomposition.non_negative_tucker</span></code></a>).</p>
<p>Using the same tensor as previously, we will perform a rank [2, 3]-decomposition of <cite>tensor</cite>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tensorly.decomposition</span> <span class="kn">import</span> <span class="n">tucker</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">core</span><span class="p">,</span> <span class="n">factors</span> <span class="o">=</span> <span class="n">tucker</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="go"># The core is a smaller tensor of size (2, 3):</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">core</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(2, 3)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">len</span><span class="p">(</span><span class="n">factors</span><span class="p">)</span>
<span class="go">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">[</span><span class="n">f</span><span class="o">.</span><span class="n">shape</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">factors</span><span class="p">]</span>
<span class="go">[(12, 2), (12, 3)]</span>
</pre></div>
</div>
<p>As before, we can reconstruct a full tensor from our Tucker decomposition:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tensorly</span> <span class="kn">import</span> <span class="n">tucker_to_tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">tucker_to_tensor</span><span class="p">(</span><span class="n">core</span><span class="p">,</span> <span class="n">factors</span><span class="p">)</span>
<span class="go">[[  0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00]</span>
<span class="go"> [ -7.340e-17   2.617e-16   1.914e-16   2.475e-16   1.000e+00   1.000e+00   1.000e+00   1.000e+00   2.475e-16   2.475e-16   2.475e-16   0.000e+00]</span>
<span class="go"> [ -7.340e-17   2.617e-16   1.914e-16   2.475e-16   1.000e+00   1.000e+00   1.000e+00   1.000e+00   2.475e-16   2.475e-16   2.475e-16   0.000e+00]</span>
<span class="go"> [ -7.340e-17   2.617e-16   1.914e-16   2.475e-16   1.000e+00   1.000e+00   1.000e+00   1.000e+00   2.475e-16   2.475e-16   2.475e-16   0.000e+00]</span>
<span class="go"> [  7.746e-17   1.000e+00   1.000e+00   1.000e+00   1.000e+00   1.000e+00   1.000e+00   1.000e+00   1.000e+00   1.000e+00   1.000e+00   0.000e+00]</span>
<span class="go"> [  7.746e-17   1.000e+00   1.000e+00   1.000e+00   1.000e+00   1.000e+00   1.000e+00   1.000e+00   1.000e+00   1.000e+00   1.000e+00   0.000e+00]</span>
<span class="go"> [  7.746e-17   1.000e+00   1.000e+00   1.000e+00   1.000e+00   1.000e+00   1.000e+00   1.000e+00   1.000e+00   1.000e+00   1.000e+00   0.000e+00]</span>
<span class="go"> [  7.746e-17   1.000e+00   1.000e+00   1.000e+00   1.000e+00   1.000e+00   1.000e+00   1.000e+00   1.000e+00   1.000e+00   1.000e+00   0.000e+00]</span>
<span class="go"> [ -7.340e-17   2.617e-16   1.914e-16   2.475e-16   1.000e+00   1.000e+00   1.000e+00   1.000e+00   2.475e-16   2.475e-16   2.475e-16   0.000e+00]</span>
<span class="go"> [ -7.340e-17   2.617e-16   1.914e-16   2.475e-16   1.000e+00   1.000e+00   1.000e+00   1.000e+00   2.475e-16   2.475e-16   2.475e-16   0.000e+00]</span>
<span class="go"> [ -7.340e-17   2.617e-16   1.914e-16   2.475e-16   1.000e+00   1.000e+00   1.000e+00   1.000e+00   2.475e-16   2.475e-16   2.475e-16   0.000e+00]</span>
<span class="go"> [  0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00   0.000e+00]]</span>
</pre></div>
</div>
<p>Note that some coefficients are almost zero (10e-16) but not exactly due to numerical approximations.</p>
</section>
</section>
<section id="matrix-product-state-tensor-train-decomposition">
<h2><span class="section-number">4.3. </span>Matrix-Product-State / Tensor-Train Decomposition</h2>
<p>The tensor-train decomposition, also known as matrix product state in physics community, is a way of decompositing high order tensors into third order ones. For a order d tensor A[i1,…,id], it splits each dimension into a order 3 sub-tensor, which we called factors or cores. One of the dimension of the sub-tensor is the real physical dimension, while the other two are edges connecting the cores before and after it.</p>
<div class="math notranslate nohighlight">
\[A[i_1, \ldots, i_d] \approx \sum_{\alpha_1}\cdots\sum_{\alpha_{d-1}}G_1(i_1, \alpha_1)G_2(\alpha_1, i_2, \alpha_2)G_3(\alpha_2, i_3, \alpha_3)\cdots G_d(\alpha_{d-1},i_d)\]</div>
<p>The advantage of the TT/tensor-train decomposition is that both of its number of entries (storage) and computational time is linear in the number of dimensions, making high dimensional problem more easily addressable.</p>
<section id="implementations">
<h3><span class="section-number">4.3.1. </span>Implementations</h3>
<p>Two versions tensor train decompositions are available in TensorLy: and SVD-based decomposition method (<code class="xref py py-func docutils literal notranslate"><span class="pre">tensorly.decomposition.mps_decomposition</span></code> and a cross approximation-based method <code class="xref py py-func docutils literal notranslate"><span class="pre">tensorly.contrib.mps_decomposition_cross</span></code>).</p>
<p>Using the same tensor as previously, we will perform a rank [1,2,1]-decomposition of the shape (12,12) <cite>tensor</cite> meaning the first core has shape (1,12,2) and the second has (2,12,1).:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tensorly.decomposition</span> <span class="kn">import</span> <span class="n">matrix_product_state</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">factors</span> <span class="o">=</span> <span class="n">matrix_product_state</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">len</span><span class="p">(</span><span class="n">factors</span><span class="p">)</span>
<span class="go">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">[</span><span class="n">f</span><span class="o">.</span><span class="n">shape</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">factors</span><span class="p">]</span>
<span class="go">[(1, 12, 2), (2, 12, 1)]</span>
</pre></div>
</div>
<p>As before, we can reconstruct a full tensor from our Tensor-train  decomposition:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>  <span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">tensorly</span> <span class="kn">import</span> <span class="n">tt_to_tensor</span>
  <span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">tt_to_tensor</span><span class="p">(</span><span class="n">factors</span><span class="p">),</span> <span class="n">decimals</span><span class="o">=</span><span class="mi">10</span><span class="p">))</span>
<span class="p">[</span> <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span><span class="p">]</span>
<span class="p">[</span> <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span><span class="p">]</span>
<span class="p">[</span> <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span><span class="p">]</span>
<span class="p">[</span><span class="o">-</span><span class="mf">0.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span> <span class="o">-</span><span class="mf">0.</span><span class="p">]</span>
<span class="p">[</span><span class="o">-</span><span class="mf">0.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span> <span class="o">-</span><span class="mf">0.</span><span class="p">]</span>
<span class="p">[</span><span class="o">-</span><span class="mf">0.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span> <span class="o">-</span><span class="mf">0.</span><span class="p">]</span>
<span class="p">[</span><span class="o">-</span><span class="mf">0.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span> <span class="o">-</span><span class="mf">0.</span><span class="p">]</span>
<span class="p">[</span> <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span><span class="p">]</span>
<span class="p">[</span> <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span><span class="p">]</span>
<span class="p">[</span> <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span><span class="p">]</span>
<span class="p">[</span> <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span><span class="p">]]</span>
</pre></div>
</div>
<p>Note that for the matrix case, TT/tensor-train decomposition is equivalent to a the singular value decomposition. This matrix is rank 2, so it can be fully recovered with a rank-2 decomposition.</p>
</section>
</section>
<section id="references">
<h2><span class="section-number">4.4. </span>References</h2>
<dl class="footnote brackets">
<dt class="label" id="id3"><span class="brackets">1</span><span class="fn-backref">(<a href="#id1">1</a>,<a href="#id2">2</a>)</span></dt>
<dd><p>T.G.Kolda and B.W.Bader, “Tensor Decompositions and Applications”,
SIAM REVIEW, vol. 51, n. 3, pp. 455-500, 2009.</p>
</dd>
</dl>
</section>
</section>


        </div>

		
        <nav class="pagination" role="navigation" aria-label="pagination">
    
    <a class="button is-medium pagination-previous" href="tensor_basics.html" title="previous page" accesskey="p">
        <span class="icon">
            <i class="fa fa-arrow-circle-left"></i>
        </span>
        <span><span class="section-number">3. </span>Tensor basics</span>
    </a>
    
    
    <a class="button is-medium pagination-next" href="tensor_regression.html" title="next page" accesskey="n">
        <span><span class="section-number">5. </span>Tensor regression </span>
        <span class="icon">
            <i class="fa fa-arrow-circle-right"></i>
        </span>
    </a>
    
</nav>

        

      </section>

        <footer class="footer">
    <div class="content has-text-centered">
        <div class="block">
          &copy; Copyright 2016 - 2021, TensorLy Developers.<br/>
        </div>
    </div>
  </footer>

    </div>

	
    
    <div class="column is-hidden-touch is-2-desktop is-one-fifth-widescreen" id="localtoc-column">

    <aside class="sticky-nav localtoc">  
        <div class="menu menu-list">
        <p class="menu-label">On this page</p>
        <ul>
<li><a class="reference internal" href="#">4. Tensor decomposition</a><ul>
<li><a class="reference internal" href="#cp-form-of-a-tensor">4.1. CP form of a tensor</a><ul>
<li><a class="reference internal" href="#candecomp-parafac-decomposition">4.1.1. CANDECOMP-PARAFAC decomposition</a></li>
</ul>
</li>
<li><a class="reference internal" href="#tucker-form-of-a-tensor">4.2. Tucker form of a tensor</a><ul>
<li><a class="reference internal" href="#tucker-decomposition">4.2.1. Tucker decomposition</a></li>
</ul>
</li>
<li><a class="reference internal" href="#matrix-product-state-tensor-train-decomposition">4.3. Matrix-Product-State / Tensor-Train Decomposition</a><ul>
<li><a class="reference internal" href="#implementations">4.3.1. Implementations</a></li>
</ul>
</li>
<li><a class="reference internal" href="#references">4.4. References</a></li>
</ul>
</li>
</ul>

        </div>
    </aside>
    </div>

    

  </div>
  </div>

  <!-- Include here scripts that need to be added after the page is loaded -->
  <script>
    function toggle_sidebar() {
        var element = document.getElementById("sidebar");
        var container = document.getElementById("column-container");
        var localtoccolumn = document.getElementById("localtoc-column");
        element.classList.toggle("hide-tablet");
        element.classList.toggle("is-hidden-mobile");
        container.classList.toggle("sidemenu-hidden");
        localtoccolumn.classList.toggle("is-one-fifth-widescreen");
        localtoccolumn.classList.toggle("is-2-desktop");
        localtoccolumn.classList.toggle("is-3-desktop");
    }
  </script> 



  </body>
</html>