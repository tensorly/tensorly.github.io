<!DOCTYPE html>

<html lang="en" data-content_root="../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>6. Sparse Backend &#8212; TensorLy: Tensor Learning in Python</title> 
<link rel="stylesheet" href="../_static/tensorly_style.css">
<link rel="apple-touch-icon" sizes="180x180" href="../_static/favicon/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="../_static/favicon/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="../_static/favicon/favicon-16x16.png">
<link rel="manifest" href="../_static/favicon/site.webmanifest">
<link rel="mask-icon" href="../_static/favicon/safari-pinned-tab.svg" color="#5bbad5">
<link rel="shortcut icon" href="../_static/favicon/favicon.ico">
<meta name="theme-color" content="#ffffff">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/tensorly_style.css?v=a02e9698" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />

  
    <script src="../_static/documentation_options.js?v=ec16d22d"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
 <script src="../_static/navbar_burger.js"></script>
 <script defer src="https://use.fontawesome.com/releases/v5.14.0/js/all.js"></script>
 
<script async src="https://www.googletagmanager.com/gtag/js?id=G-3V91QCZR03"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-3V91QCZR03');
</script>
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="API reference" href="../modules/api.html" />
    <link rel="prev" title="5. Tensor regression" href="tensor_regression.html" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">

  </head>
<body  class="has-navbar-fixed-top">

  <header>
    <navbar>
      <nav class="navbar top-navbar is-fixed-top has-shadow is-flex-wrap-wrap" role="navigation" aria-label="main top navigation">
        <div class="navbar-brand">
        

          <a class="navbar-item" href="../index.html">
            <img src="../_static/logo_tensorly.png" height="28">
          </a>
          <a class="navbar-item is-hidden-desktop" href="https://github.com/tensorly/tensorly" target="_blank">
              <span class="icon"><i class="fab fa-github"></i></span>
          </a>

          <a role="button" class="navbar-burger" data-target="top-nav-menu" aria-label="menu" aria-expanded="false">
            <span aria-hidden="true"></span>
            <span aria-hidden="true"></span>
            <span aria-hidden="true"></span>
          </a>

        </div>
        
        <div class="navbar-menu" id="top-nav-menu">
        

          <div class="navbar-start">
            
              <a class="navbar-item" href="../installation.html">
              Install
            </a>
              <a class="navbar-item" href="index.html">
              User Guide
            </a>
              <a class="navbar-item" href="../modules/api.html">
              API
            </a>
              <a class="navbar-item" href="../auto_examples/index.html">
              Examples
            </a>
              <a class="navbar-item" href="../about.html">
              About Us
            </a>
            <div class="navbar-item has-dropdown is-hoverable is-boxed">
              <a class="navbar-link">
                Ecosystem
              </a>
              <div class="navbar-dropdown top-navbar">
                <a class="navbar-item" href="http://tensorly.org/torch" target="_blank">
                  TensorLy-Torch
                </a>
                <a class="navbar-item" href="http://tensorly.org/quantum" target="_blank">
                  TensorLy-Quantum
                </a>
                <a class="navbar-item" href="http://tensorly.org/viz" target="_blank">
                  TensorLy-Viz
                </a>
                <a class="navbar-item" href="https://github.com/JeanKossaifi/tensorly-notebooks" target="_blank">
                  Notebooks
                </a>
              </div>
            </div>
          </div>
        
          <div class="navbar-end">
            <div class="navbar-item">
            
            <a class="button is-hidden-touch is-dark" href="https://github.com/tensorly/tensorly" target="_blank">
              <span class="icon-text">
                <span class="icon is-large">
                  <i class="fab fa-github"></i>
                </span>
                <span>Github</span>
              </span>
            </a>

            </div> 
          </div> 
        </div> 

      </nav>
      
    </navbar>
  </header>


  <div id="column-container">
  <div class="columns is-mobile is-centered">
	
  
      <div class="column is-10-mobile is-one-third-tablet is-3-desktop is-hidden-mobile" id="sidebar">
    
    <aside class="sticky-nav sidebar-menu">
<div class="sidebar-search">
  <form class="field" id="searchbox" role="search" action="../search.html" method="get">
    <!-- <label class="label" id="searchlabel">Quick search</label> -->
    <div class="field has-addons">
      <div class="control is-expanded">
        <input class="input" type="text" placeholder="Search in TensorLy" name="q" aria-labelledby="searchlabel autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      </div>
      <div class="control">
        <input class="button is-info" type="submit" value="Go" />
      </div>
    </div>
  </form>
  <script>document.getElementById('searchbox').style.display = "block"</script>

</div>
      
      <div class="sidebar-menu-toc">
      <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installing tensorly</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">User guide</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="quickstart.html">1. Quick-Start</a></li>
<li class="toctree-l2"><a class="reference internal" href="backend.html">2. TensorLy’s backend system</a></li>
<li class="toctree-l2"><a class="reference internal" href="tensor_basics.html">3. Tensor basics</a></li>
<li class="toctree-l2"><a class="reference internal" href="tensor_decomposition.html">4. Tensor decomposition</a></li>
<li class="toctree-l2"><a class="reference internal" href="tensor_regression.html">5. Tensor regression</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">6. Sparse Backend</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../modules/api.html">API reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_examples/index.html">Gallery of examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../development_guide/index.html">Development guide</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/JeanKossaifi/tensorly-notebooks">Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../about.html">About us</a></li>
</ul>
 
      </div>
    </aside>
  </div>
  

  <div class="column main-column">

    
    <div class="main-section">

      
      
      <div class="side-menu-toggle">
        <button class="button" id="toggle-sidebar" onclick="toggle_sidebar()">
          <span class="icon"><i class="fa fa-bars" aria-hidden="true"></i></span>
          <span>menu</span> 
        </button>
      </div>
      

      <div class="container content main-content">
        
  <section id="sparse-backend">
<span id="id1"></span><h1><span class="section-number">6. </span>Sparse Backend</h1>
<p>TensorLy supports sparse tensors for some backends and algorithms.</p>
<p>When selecting a backend to be used for tensorly, this backend will also
be applied to the sparse implementations. This is because many backends
natively support both dense and sparse tensors as distinct objects. For example,
TensorFlow and PyTorch both have (some) support for sparse tensors.
Using TensorLy’s dense or sparse interfaces will give you
appropriate objects for the selected backend.</p>
<section id="why-a-separate-sparse-backend">
<h2><span class="section-number">6.1. </span>Why a separate sparse backend?</h2>
<p>Some algorithms need to be adapted to be <em>sparse-safe</em>.</p>
<p>In addition, not all backends have a native sparse representation. For instance,
NumPy lacks a sparse array structure.
In these cases, TensorLy makes opinionated decisions
about how to handle sparse support, if at all. It is usually necessary for
non-native sparse support to require additional dependencies. For the NumPy
backend, the <a class="reference external" href="https://sparse.pydata.org">PyData/Sparse</a> project is used
as the sparse representation.</p>
</section>
<section id="algorithms">
<h2><span class="section-number">6.2. </span>Algorithms</h2>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">parafac</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">non_negative_parafac</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">partial_tucker</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">robust_pca</span></code></p></li>
</ul>
<section id="usage">
<h3><span class="section-number">6.2.1. </span>Usage</h3>
<p>The sparse sub-package in <code class="docutils literal notranslate"><span class="pre">tensorly.contrib.sparse</span></code> contains a mirror of the
interfaces in the usual, dense <code class="docutils literal notranslate"><span class="pre">tensorly</span></code> package. For example, unfolding a
sparse tensor would use:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">sparse</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tensorly.contrib.sparse</span> <span class="kn">import</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">unfold</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">sparse</span><span class="o">.</span><span class="n">COO</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">24</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">sparse</span><span class="o">.</span><span class="n">COO</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">coords</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">unfold</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">data</span> <span class="c1"># mode-1 unfolding</span>
<span class="go">array([[ 0,  1,  2,  3,  4,  5,  6,  7],</span>
<span class="go">       [ 8,  9, 10, 11, 12, 13, 14, 15],</span>
<span class="go">       [16, 17, 18, 19, 20, 21, 22, 23]])</span>
</pre></div>
</div>
<p>This separation makes it explicit whether a sparse or dense algorithm is
being used.</p>
<p>Note that not all algorithms currently support sparse. This is because some
algorithms may need to be rewritten to properly avoid densifying large sparse
arrays, or creating arrays with large shapes. The algorithms listed above have
been tested with sparse tensors. Other algorithms may work, but one should be
careful to watch tensorly’s memory usage when using them.</p>
<p>With the PyData/Sparse backend, you can set the environment variable
<code class="docutils literal notranslate"><span class="pre">SPARSE_AUTO_DENSIFY=0</span></code> before importing <code class="docutils literal notranslate"><span class="pre">sparse</span></code> and it will cause it to
raise a <code class="docutils literal notranslate"><span class="pre">RuntimeError</span></code> whenever a sparse tensor would be automatically
densified. However, be aware that this does not protect against an algorithm
attempting to create a new dense array with a large shape.</p>
<p>Another caveat to be aware of is that some algorithms may perform better with
the dense variant, even when using sparse arrays. For example, the <code class="docutils literal notranslate"><span class="pre">parafac</span></code>
algorithm has been written so as to avoid large memory usage for dense arrays.
However, because the resulting decomposed vectors will generally be dense even
if the input tensor is sparse. Thus, using the sparse <code class="docutils literal notranslate"><span class="pre">parafac</span></code>
(<code class="docutils literal notranslate"><span class="pre">tensorly.contrib.sparse.decomposition.parafac</span></code>) may be slower and use more
memory than the dense version (<code class="docutils literal notranslate"><span class="pre">tensorly.decomposition.parafac</span></code>) for a
sparse input tensor.</p>
</section>
</section>
<section id="missing-values">
<h2><span class="section-number">6.3. </span>Missing Values</h2>
<p>The <code class="docutils literal notranslate"><span class="pre">parafac</span></code> function supports masks for missing values. A mask should be a
boolean array of the same shape as the original tensor that is <code class="docutils literal notranslate"><span class="pre">False</span></code>/<code class="docutils literal notranslate"><span class="pre">0</span></code>
where the value is missing and <code class="docutils literal notranslate"><span class="pre">True</span></code>/<code class="docutils literal notranslate"><span class="pre">1</span></code> where it is not. It is passed to
the <code class="docutils literal notranslate"><span class="pre">parafac()</span></code> function via the <code class="docutils literal notranslate"><span class="pre">mask</span></code> parameter.</p>
<p>When using masks with sparse tensors, there are two important caveats:</p>
<ul class="simple">
<li><p>The mask itself should be sparse. In the algorithm, the memory used will be
proportional to the number of missing values. Values of the original sparse
tensor that are <code class="docutils literal notranslate"><span class="pre">0</span></code> should be <code class="docutils literal notranslate"><span class="pre">True</span></code>/<code class="docutils literal notranslate"><span class="pre">1</span></code> (i.e., non-missing) in the
mask.</p></li>
<li><p>Sparse mask support is currently only supported with the sparse backend
<code class="docutils literal notranslate"><span class="pre">parafac</span></code> (<code class="docutils literal notranslate"><span class="pre">tensor.contrib.sparse.decomposition.parafac</span></code>). The dense
backend <code class="docutils literal notranslate"><span class="pre">parafac</span></code> will densify the array.</p></li>
</ul>
<section id="example">
<h3><span class="section-number">6.3.1. </span>Example</h3>
<p>In the following example, we construct a random sparse tensor that has a known
rank (by construction), and decompose it with parafac.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">tensorly.contrib.sparse</span> <span class="k">as</span> <span class="nn">stl</span><span class="p">;</span> <span class="kn">import</span> <span class="nn">sparse</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">1001</span><span class="p">,</span> <span class="mi">1002</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rank</span> <span class="o">=</span> <span class="mi">5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">starting_weights</span> <span class="o">=</span> <span class="n">stl</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">rank</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">starting_weights</span>
<span class="go">&lt;COO: shape=(5,), dtype=float64, nnz=0, fill_value=1.0&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">starting_factors</span> <span class="o">=</span> <span class="p">[</span><span class="n">sparse</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="n">i</span><span class="p">,</span> <span class="n">rank</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">shape</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">starting_factors</span>
<span class="go">[&lt;COO: shape=(1000, 5), dtype=float64, nnz=50, fill_value=0.0&gt;, &lt;COO: shape=(1001, 5), dtype=float64, nnz=50, fill_value=0.0&gt;, &lt;COO: shape=(1002, 5), dtype=float64, nnz=50, fill_value=0.0&gt;]</span>
</pre></div>
</div>
<p>Here we construct a tensor from the random factors. Note that in general,
a recomposed tensor will be dense, but for our constructed example it is
sparse, so we can use <code class="docutils literal notranslate"><span class="pre">cp_to_tensor</span></code> without worrying about using too
much memory.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tensorly.contrib.sparse.cp_tensor</span> <span class="kn">import</span> <span class="n">cp_to_tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tensor</span> <span class="o">=</span> <span class="n">cp_to_tensor</span><span class="p">((</span><span class="n">starting_weights</span><span class="p">,</span> <span class="n">starting_factors</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tensor</span>
<span class="go">&lt;COO: shape=(1000, 1001, 1002), dtype=float64, nnz=5044, fill_value=0.0&gt;</span>
</pre></div>
</div>
<p>This is how much memory the sparse array takes up, vs. how much it would take
up if it were represented densely.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">tensor</span><span class="o">.</span><span class="n">nbytes</span> <span class="o">/</span> <span class="mf">1e9</span> <span class="c1"># Actual memory usage in GB</span>
<span class="go">0.000161408</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="mi">8</span> <span class="o">/</span> <span class="mf">1e9</span> <span class="c1"># Memory usage if array was dense, in GB</span>
<span class="go">8.024016</span>
</pre></div>
</div>
<p>Now to decompose the tensor.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tensorly.decomposition</span> <span class="kn">import</span> <span class="n">parafac</span> <span class="c1"># The dense version</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">time</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">();</span> <span class="n">dense_cp</span> <span class="o">=</span> <span class="n">parafac</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;random&#39;</span><span class="p">);</span> <span class="nb">print</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t</span><span class="p">)</span>
<span class="go">1.3858051300048828</span>
</pre></div>
</div>
<p>Note that the decomposition takes much longer when using the sparse variant.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tensorly.contrib.sparse.decomposition</span> <span class="kn">import</span> <span class="n">parafac</span> <span class="k">as</span> <span class="n">sparse_parafac</span> <span class="c1"># The sparse version</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">();</span> <span class="n">sparse_cp</span> <span class="o">=</span> <span class="n">sparse_parafac</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;random&#39;</span><span class="p">);</span> <span class="nb">print</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t</span><span class="p">)</span>
<span class="go">14.053689002990723</span>
</pre></div>
</div>
<p>However, there can be advantages to using the sparse variant. It is currently
required when using <code class="docutils literal notranslate"><span class="pre">init='svd'</span></code> to make TensorLy use the sparse SVD
algorithm (from <code class="docutils literal notranslate"><span class="pre">scipy.sparse</span></code>). Choosing the sparse backend <code class="docutils literal notranslate"><span class="pre">parafac</span></code>
also makes it use <code class="docutils literal notranslate"><span class="pre">scipy.sparse.linalg.spsolve</span></code> instead of
<code class="docutils literal notranslate"><span class="pre">numpy.linalg.solve</span></code>, which can have advantages, for instance, when using
the scikit-umfpack backend, it is more robust against nearly singular
intermediate matrices.</p>
</section>
</section>
</section>


      </div>

      
        <nav class="pagination" role="navigation" aria-label="pagination">
    
    <a class="button pagination-previous" href="tensor_regression.html" title="previous page" accesskey="p">
        <span class="icon">
            <i class="fa fa-arrow-circle-left"></i>
        </span>
        <span><span class="section-number">5. </span>Tensor regression</span>
    </a>
    
    
    <a class="button pagination-next" href="../modules/api.html" title="next page" accesskey="n">
        <span>API reference </span>
        <span class="icon">
            <i class="fa fa-arrow-circle-right"></i>
        </span>
    </a>
    
</nav>

      

        <footer class="footer">
    <div class="content has-text-centered">
        <div class="block">
          &copy; Copyright 2016 - 2024, TensorLy Developers.<br/>
        </div>
    </div>
  </footer>

    </div>

  </div>  

	
    
    <div class="column is-hidden-touch is-2-desktop is-one-fifth-widescreen" id="localtoc-column">

    <aside class="sticky-nav localtoc"> 
        <p class="menu-label"> 
            <span class="icon-text">
                <span class="icon"><i class="fas fa-duotone fa-list"></i></span>
                <span> On this page </span>
            </span>
        </p>

        <div class="menu menu-list localtoc-list">
        <ul>
<li><a class="reference internal" href="#">6. Sparse Backend</a><ul>
<li><a class="reference internal" href="#why-a-separate-sparse-backend">6.1. Why a separate sparse backend?</a></li>
<li><a class="reference internal" href="#algorithms">6.2. Algorithms</a><ul>
<li><a class="reference internal" href="#usage">6.2.1. Usage</a></li>
</ul>
</li>
<li><a class="reference internal" href="#missing-values">6.3. Missing Values</a><ul>
<li><a class="reference internal" href="#example">6.3.1. Example</a></li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
    </aside>
    </div>

  

  </div>  
  </div> 

  
  <script>
    function toggle_sidebar() {
        var element = document.getElementById("sidebar");
        var container = document.getElementById("column-container");
        var localtoccolumn = document.getElementById("localtoc-column");
        element.classList.toggle("hide-tablet");
        element.classList.toggle("is-hidden-mobile");
        container.classList.toggle("sidemenu-hidden");
        localtoccolumn.classList.toggle("is-one-fifth-widescreen");
        localtoccolumn.classList.toggle("is-2-desktop");
        localtoccolumn.classList.toggle("is-3-desktop");
    }
  </script> 



  </body>
</html>